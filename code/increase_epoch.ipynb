{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch import optim\nfrom torch import Tensor\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torchvision.models import resnet\nfrom torchvision.models.resnet import Bottleneck\nfrom torchvision.models.resnet import BasicBlock\nfrom torchvision.models.resnet import resnet18\n\nfrom typing import Type, Any, Callable, Union, List, Optional\n\nimport time\n\nclass ResNet(nn.Module):\n\n    def __init__(\n        self,\n        block: Type[Union[BasicBlock, Bottleneck]],\n        layers: List[int],\n        num_classes: int = 10,\n        zero_init_residual: bool = False,\n        groups: int = 1,\n        width_per_group: int = 64,\n        replace_stride_with_dilation: Optional[List[bool]] = None,\n        norm_layer: Optional[Callable[..., nn.Module]] = None\n    ) -> None:\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n\n    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def _forward_impl(self, x: Tensor) -> Tensor:\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n  \n     \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n    def forward(self, x: Tensor) -> Tensor:\n        return self._forward_impl(x)\n\n\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=2)\n\n\n\nmixup_alpha = 1.0\n\ndef mixup_data(x, y):\n    lam = np.random.beta(mixup_alpha, mixup_alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).cuda()\n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n    def forward(self, y, targets, smoothing=0.1):\n        confidence = 1. - smoothing\n        log_probs = F.log_softmax(y, dim=-1) # 예측 확률 계산\n        true_probs = torch.zeros_like(log_probs)\n        true_probs.fill_(smoothing / (y.shape[1] - 1))\n        true_probs.scatter_(1, targets.data.unsqueeze(1), confidence) # 정답 인덱스의 정답 확률을 confidence로 변경\n        return torch.mean(torch.sum(true_probs * -log_probs, dim=-1)) # negative log likelihood\n\n    \n\ndevice = 'cuda'\n\nnet = resnet18()\nnet = net.to(device)\n\nlearning_rate = 0.1\n\n\ncriterion = LabelSmoothingCrossEntropy()\noptimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n\ndef train(epoch):\n    print('\\n[ Train epoch: %d ]' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets)\n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        \n        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        \n        loss.backward()\n\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n\n        total += targets.size(0)\n        current_correct = (lam * predicted.eq(targets_a).sum().item() + (1 - lam) * predicted.eq(targets_b).sum().item())\n        correct += current_correct\n\n        \n\n    print('\\nTotal average train accuarcy:', correct / total)\n    print('Total average train loss:', train_loss / total)\n\n\ndef test(epoch):\n    print('\\n[ Test epoch: %d ]' % epoch)\n    net.eval()\n    loss = 0\n    correct = 0\n    total = 0\n\n    for batch_idx, (inputs, targets) in enumerate(test_loader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        total += targets.size(0)\n\n        outputs = net(inputs)\n        loss += criterion(outputs, targets).item()\n\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(targets).sum().item()\n\n    print('\\nTotal average test accuarcy:', correct / total)\n    print('Total average test loss:', loss / total)\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    lr = learning_rate\n    if epoch >= 50:\n        lr /= 10\n    if epoch >= 100:\n        lr /= 10\n    if epoch >= 150:\n        lr /= 10\n    \n        \n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\nstart_time = time.time()\n\nfor epoch in range(0, 200):\n    adjust_learning_rate(optimizer, epoch)\n    train(epoch)\n    test(epoch)\n    print('\\nTime elapsed:', time.time() - start_time)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T05:18:19.329463Z","iopub.execute_input":"2021-07-15T05:18:19.329826Z","iopub.status.idle":"2021-07-15T06:08:30.438412Z","shell.execute_reply.started":"2021-07-15T05:18:19.329766Z","shell.execute_reply":"2021-07-15T06:08:30.436243Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n\n[ Train epoch: 0 ]\n\nTotal average train accuarcy: 0.2009436827628956\nTotal average train loss: 0.032145758810043334\n\n[ Test epoch: 0 ]\n\nTotal average test accuarcy: 0.3081\nTotal average test loss: 0.002748925757408142\n\nTime elapsed: 24.124150037765503\n\n[ Train epoch: 1 ]\n\nTotal average train accuarcy: 0.2943139728578913\nTotal average train loss: 0.027833640146255494\n\n[ Test epoch: 1 ]\n\nTotal average test accuarcy: 0.2779\nTotal average test loss: 0.004087410974502563\n\nTime elapsed: 47.95303702354431\n\n[ Train epoch: 2 ]\n\nTotal average train accuarcy: 0.3403729185970827\nTotal average train loss: 0.026965589365959167\n\n[ Test epoch: 2 ]\n\nTotal average test accuarcy: 0.4009\nTotal average test loss: 0.0029038627147674563\n\nTime elapsed: 71.82047009468079\n\n[ Train epoch: 3 ]\n\nTotal average train accuarcy: 0.3761452741974994\nTotal average train loss: 0.026305746755599976\n\n[ Test epoch: 3 ]\n\nTotal average test accuarcy: 0.4646\nTotal average test loss: 0.0026608293771743776\n\nTime elapsed: 94.89051532745361\n\n[ Train epoch: 4 ]\n\nTotal average train accuarcy: 0.4016502852866117\nTotal average train loss: 0.02584088357448578\n\n[ Test epoch: 4 ]\n\nTotal average test accuarcy: 0.5172\nTotal average test loss: 0.0022504580736160277\n\nTime elapsed: 118.72467589378357\n\n[ Train epoch: 5 ]\n\nTotal average train accuarcy: 0.4254877257183029\nTotal average train loss: 0.025385609436035156\n\n[ Test epoch: 5 ]\n\nTotal average test accuarcy: 0.5376\nTotal average test loss: 0.0022236881256103517\n\nTime elapsed: 142.86818265914917\n\n[ Train epoch: 6 ]\n\nTotal average train accuarcy: 0.45198051202532524\nTotal average train loss: 0.02491496089220047\n\n[ Test epoch: 6 ]\n\nTotal average test accuarcy: 0.5984\nTotal average test loss: 0.0021539090156555175\n\nTime elapsed: 166.0301594734192\n\n[ Train epoch: 7 ]\n\nTotal average train accuarcy: 0.470953075025971\nTotal average train loss: 0.024552161045074464\n\n[ Test epoch: 7 ]\n\nTotal average test accuarcy: 0.4168\nTotal average test loss: 0.002526970314979553\n\nTime elapsed: 189.90962553024292\n\n[ Train epoch: 8 ]\n\nTotal average train accuarcy: 0.4558066958055789\nTotal average train loss: 0.024923056650161743\n\n[ Test epoch: 8 ]\n\nTotal average test accuarcy: 0.5989\nTotal average test loss: 0.0021111634969711306\n\nTime elapsed: 213.12242603302002\n\n[ Train epoch: 9 ]\n\nTotal average train accuarcy: 0.48959560587945794\nTotal average train loss: 0.02425046812057495\n\n[ Test epoch: 9 ]\n\nTotal average test accuarcy: 0.5854\nTotal average test loss: 0.002150498604774475\n\nTime elapsed: 236.19518947601318\n\n[ Train epoch: 10 ]\n\nTotal average train accuarcy: 0.4992702408341323\nTotal average train loss: 0.024016179904937745\n\n[ Test epoch: 10 ]\n\nTotal average test accuarcy: 0.7025\nTotal average test loss: 0.001870732069015503\n\nTime elapsed: 261.0467481613159\n\n[ Train epoch: 11 ]\n\nTotal average train accuarcy: 0.5139519072293794\nTotal average train loss: 0.023706825098991396\n\n[ Test epoch: 11 ]\n\nTotal average test accuarcy: 0.6387\nTotal average test loss: 0.0019973827600479124\n\nTime elapsed: 283.4652450084686\n\n[ Train epoch: 12 ]\n\nTotal average train accuarcy: 0.5243111369070238\nTotal average train loss: 0.02357168580532074\n\n[ Test epoch: 12 ]\n\nTotal average test accuarcy: 0.6926\nTotal average test loss: 0.0019268296718597411\n\nTime elapsed: 306.9742045402527\n\n[ Train epoch: 13 ]\n\nTotal average train accuarcy: 0.5231492826262382\nTotal average train loss: 0.02351732899427414\n\n[ Test epoch: 13 ]\n\nTotal average test accuarcy: 0.6199\nTotal average test loss: 0.002085248422622681\n\nTime elapsed: 331.2229347229004\n\n[ Train epoch: 14 ]\n\nTotal average train accuarcy: 0.5202814462104967\nTotal average train loss: 0.023627795629501343\n\n[ Test epoch: 14 ]\n\nTotal average test accuarcy: 0.6176\nTotal average test loss: 0.002067637896537781\n\nTime elapsed: 355.22175455093384\n\n[ Train epoch: 15 ]\n\nTotal average train accuarcy: 0.5399973538232556\nTotal average train loss: 0.023133948447704316\n\n[ Test epoch: 15 ]\n\nTotal average test accuarcy: 0.6659\nTotal average test loss: 0.0019633893609046936\n\nTime elapsed: 378.1598379611969\n\n[ Train epoch: 16 ]\n\nTotal average train accuarcy: 0.5458310293360638\nTotal average train loss: 0.023120483918190004\n\n[ Test epoch: 16 ]\n\nTotal average test accuarcy: 0.7256\nTotal average test loss: 0.001812750494480133\n\nTime elapsed: 401.1595690250397\n\n[ Train epoch: 17 ]\n\nTotal average train accuarcy: 0.5514053321237347\nTotal average train loss: 0.022873137590885162\n\n[ Test epoch: 17 ]\n\nTotal average test accuarcy: 0.6969\nTotal average test loss: 0.0018577934861183166\n\nTime elapsed: 425.92626667022705\n\n[ Train epoch: 18 ]\n\nTotal average train accuarcy: 0.5475145348923244\nTotal average train loss: 0.022966423535346985\n\n[ Test epoch: 18 ]\n\nTotal average test accuarcy: 0.6779\nTotal average test loss: 0.0019471100568771362\n\nTime elapsed: 448.49250960350037\n\n[ Train epoch: 19 ]\n\nTotal average train accuarcy: 0.5543315968330685\nTotal average train loss: 0.022771596660614013\n\n[ Test epoch: 19 ]\n\nTotal average test accuarcy: 0.648\nTotal average test loss: 0.0020138172149658205\n\nTime elapsed: 472.0504982471466\n\n[ Train epoch: 20 ]\n\nTotal average train accuarcy: 0.5583823839434302\nTotal average train loss: 0.022765564198493956\n\n[ Test epoch: 20 ]\n\nTotal average test accuarcy: 0.7023\nTotal average test loss: 0.0018514393448829651\n\nTime elapsed: 496.37262415885925\n\n[ Train epoch: 21 ]\n\nTotal average train accuarcy: 0.5626784587704213\nTotal average train loss: 0.022695348544120787\n\n[ Test epoch: 21 ]\n\nTotal average test accuarcy: 0.7124\nTotal average test loss: 0.001858227038383484\n\nTime elapsed: 519.5197303295135\n\n[ Train epoch: 22 ]\n\nTotal average train accuarcy: 0.559379941579828\nTotal average train loss: 0.022716430723667146\n\n[ Test epoch: 22 ]\n\nTotal average test accuarcy: 0.7087\nTotal average test loss: 0.0018626913666725158\n\nTime elapsed: 542.8689453601837\n\n[ Train epoch: 23 ]\n\nTotal average train accuarcy: 0.5609141447644648\nTotal average train loss: 0.022755010874271394\n\n[ Test epoch: 23 ]\n\nTotal average test accuarcy: 0.7236\nTotal average test loss: 0.0018298115849494933\n\nTime elapsed: 567.0843138694763\n\n[ Train epoch: 24 ]\n\nTotal average train accuarcy: 0.5524898461145026\nTotal average train loss: 0.022856042528152466\n\n[ Test epoch: 24 ]\n\nTotal average test accuarcy: 0.641\nTotal average test loss: 0.0019939992189407347\n\nTime elapsed: 590.1375782489777\n\n[ Train epoch: 25 ]\n\nTotal average train accuarcy: 0.5640133686846408\nTotal average train loss: 0.022634159734249114\n\n[ Test epoch: 25 ]\n\nTotal average test accuarcy: 0.5534\nTotal average test loss: 0.00230885808467865\n\nTime elapsed: 613.719628572464\n\n[ Train epoch: 26 ]\n\nTotal average train accuarcy: 0.562716929697579\nTotal average train loss: 0.0226502947807312\n\n[ Test epoch: 26 ]\n\nTotal average test accuarcy: 0.6908\nTotal average test loss: 0.0019138949036598206\n\nTime elapsed: 637.2294471263885\n\n[ Train epoch: 27 ]\n\nTotal average train accuarcy: 0.5666346480235543\nTotal average train loss: 0.022565301382541657\n\n[ Test epoch: 27 ]\n\nTotal average test accuarcy: 0.6911\nTotal average test loss: 0.0018951695561408998\n\nTime elapsed: 660.513763666153\n\n[ Train epoch: 28 ]\n\nTotal average train accuarcy: 0.5730850544948016\nTotal average train loss: 0.02244470464706421\n\n[ Test epoch: 28 ]\n\nTotal average test accuarcy: 0.7\nTotal average test loss: 0.0018664817214012145\n\nTime elapsed: 684.7709009647369\n\n[ Train epoch: 29 ]\n\nTotal average train accuarcy: 0.5630999636623064\nTotal average train loss: 0.0226631498670578\n\n[ Test epoch: 29 ]\n\nTotal average test accuarcy: 0.6382\nTotal average test loss: 0.0020120236039161683\n\nTime elapsed: 708.5626127719879\n\n[ Train epoch: 30 ]\n\nTotal average train accuarcy: 0.5632535742618069\nTotal average train loss: 0.022695387654304504\n\n[ Test epoch: 30 ]\n\nTotal average test accuarcy: 0.7224\nTotal average test loss: 0.0018154475688934326\n\nTime elapsed: 732.5400590896606\n\n[ Train epoch: 31 ]\n\nTotal average train accuarcy: 0.5783795076075652\nTotal average train loss: 0.02237128998756409\n\n[ Test epoch: 31 ]\n\nTotal average test accuarcy: 0.6939\nTotal average test loss: 0.001880742084980011\n\nTime elapsed: 755.8611772060394\n\n[ Train epoch: 32 ]\n\nTotal average train accuarcy: 0.5702569532950785\nTotal average train loss: 0.022511168382167816\n\n[ Test epoch: 32 ]\n\nTotal average test accuarcy: 0.6238\nTotal average test loss: 0.002083500385284424\n\nTime elapsed: 779.350448846817\n\n[ Train epoch: 33 ]\n\nTotal average train accuarcy: 0.5736359269227402\nTotal average train loss: 0.022423500809669494\n\n[ Test epoch: 33 ]\n\nTotal average test accuarcy: 0.6581\nTotal average test loss: 0.0019776217579841613\n\nTime elapsed: 803.0373213291168\n\n[ Train epoch: 34 ]\n\nTotal average train accuarcy: 0.5769378958041079\nTotal average train loss: 0.022411149742603304\n\n[ Test epoch: 34 ]\n\nTotal average test accuarcy: 0.6803\nTotal average test loss: 0.0019305591225624085\n\nTime elapsed: 826.2625856399536\n\n[ Train epoch: 35 ]\n\nTotal average train accuarcy: 0.5757171201509832\nTotal average train loss: 0.022349012746810913\n\n[ Test epoch: 35 ]\n\nTotal average test accuarcy: 0.7157\nTotal average test loss: 0.0018545968174934386\n\nTime elapsed: 850.5786395072937\n\n[ Train epoch: 36 ]\n\nTotal average train accuarcy: 0.5712394291871483\nTotal average train loss: 0.022504216890335084\n\n[ Test epoch: 36 ]\n\nTotal average test accuarcy: 0.7031\nTotal average test loss: 0.0018408968448638916\n\nTime elapsed: 873.3614733219147\n\n[ Train epoch: 37 ]\n\nTotal average train accuarcy: 0.5774886459314857\nTotal average train loss: 0.022343196399211885\n\n[ Test epoch: 37 ]\n\nTotal average test accuarcy: 0.7289\nTotal average test loss: 0.0017984570622444152\n\nTime elapsed: 896.653862953186\n\n[ Train epoch: 38 ]\n\nTotal average train accuarcy: 0.5716369801976722\nTotal average train loss: 0.022493199927806854\n\n[ Test epoch: 38 ]\n\nTotal average test accuarcy: 0.7292\nTotal average test loss: 0.001805829882621765\n\nTime elapsed: 921.5504126548767\n\n[ Train epoch: 39 ]\n\nTotal average train accuarcy: 0.5814782841854395\nTotal average train loss: 0.02229809494256973\n\n[ Test epoch: 39 ]\n\nTotal average test accuarcy: 0.6691\nTotal average test loss: 0.001965686547756195\n\nTime elapsed: 943.9370210170746\n\n[ Train epoch: 40 ]\n\nTotal average train accuarcy: 0.5802582538807878\nTotal average train loss: 0.022295361936092377\n\n[ Test epoch: 40 ]\n\nTotal average test accuarcy: 0.6695\nTotal average test loss: 0.002006880509853363\n\nTime elapsed: 967.4474132061005\n\n[ Train epoch: 41 ]\n\nTotal average train accuarcy: 0.5717969683318356\nTotal average train loss: 0.022443388404846193\n\n[ Test epoch: 41 ]\n\nTotal average test accuarcy: 0.6916\nTotal average test loss: 0.0019120739936828613\n\nTime elapsed: 991.7085294723511\n\n[ Train epoch: 42 ]\n\nTotal average train accuarcy: 0.584679220985121\nTotal average train loss: 0.02220204958677292\n\n[ Test epoch: 42 ]\n\nTotal average test accuarcy: 0.6943\nTotal average test loss: 0.0018811206340789794\n\nTime elapsed: 1016.1211993694305\n\n[ Train epoch: 43 ]\n\nTotal average train accuarcy: 0.5757882632866483\nTotal average train loss: 0.02236461724281311\n\n[ Test epoch: 43 ]\n\nTotal average test accuarcy: 0.5925\nTotal average test loss: 0.0021625156164169312\n\nTime elapsed: 1038.8760166168213\n\n[ Train epoch: 44 ]\n\nTotal average train accuarcy: 0.5778593818975396\nTotal average train loss: 0.02235258763551712\n\n[ Test epoch: 44 ]\n\nTotal average test accuarcy: 0.7166\nTotal average test loss: 0.001853266930580139\n\nTime elapsed: 1062.1173515319824\n\n[ Train epoch: 45 ]\n\nTotal average train accuarcy: 0.5815253966706473\nTotal average train loss: 0.02229036185503006\n\n[ Test epoch: 45 ]\n\nTotal average test accuarcy: 0.6501\nTotal average test loss: 0.001999124479293823\n\nTime elapsed: 1087.1456580162048\n\n[ Train epoch: 46 ]\n\nTotal average train accuarcy: 0.583442339502277\nTotal average train loss: 0.022263659296035767\n\n[ Test epoch: 46 ]\n\nTotal average test accuarcy: 0.7447\nTotal average test loss: 0.0017775150775909425\n\nTime elapsed: 1110.2657685279846\n\n[ Train epoch: 47 ]\n\nTotal average train accuarcy: 0.584234216366545\nTotal average train loss: 0.022217806177139282\n\n[ Test epoch: 47 ]\n\nTotal average test accuarcy: 0.7598\nTotal average test loss: 0.0017842875838279724\n\nTime elapsed: 1133.2574169635773\n\n[ Train epoch: 48 ]\n\nTotal average train accuarcy: 0.5853532897837126\nTotal average train loss: 0.022158648216724395\n\n[ Test epoch: 48 ]\n\nTotal average test accuarcy: 0.7405\nTotal average test loss: 0.0018227941513061523\n\nTime elapsed: 1157.752007484436\n\n[ Train epoch: 49 ]\n\nTotal average train accuarcy: 0.5875458212057056\nTotal average train loss: 0.022142878708839416\n\n[ Test epoch: 49 ]\n\nTotal average test accuarcy: 0.734\nTotal average test loss: 0.0018160640358924865\n\nTime elapsed: 1180.9056272506714\n\n[ Train epoch: 50 ]\n\nTotal average train accuarcy: 0.6335621261746881\nTotal average train loss: 0.021018074667453767\n\n[ Test epoch: 50 ]\n\nTotal average test accuarcy: 0.8292\nTotal average test loss: 0.0015843574643135071\n\nTime elapsed: 1205.029480457306\n\n[ Train epoch: 51 ]\n\nTotal average train accuarcy: 0.6320358482648396\nTotal average train loss: 0.02101453015089035\n\n[ Test epoch: 51 ]\n\nTotal average test accuarcy: 0.8326\nTotal average test loss: 0.0015221864223480225\n\nTime elapsed: 1228.5870125293732\n\n[ Train epoch: 52 ]\n\nTotal average train accuarcy: 0.6429122324113633\nTotal average train loss: 0.02082552133321762\n\n[ Test epoch: 52 ]\n\nTotal average test accuarcy: 0.8346\nTotal average test loss: 0.0015375516653060913\n\nTime elapsed: 1251.4679718017578\n\n[ Train epoch: 53 ]\n\nTotal average train accuarcy: 0.6410915001549518\nTotal average train loss: 0.02076997918128967\n\n[ Test epoch: 53 ]\n\nTotal average test accuarcy: 0.8417\nTotal average test loss: 0.0015251244306564331\n\nTime elapsed: 1275.648307800293\n\n[ Train epoch: 54 ]\n\nTotal average train accuarcy: 0.6411084188939701\nTotal average train loss: 0.020797196230888368\n\n[ Test epoch: 54 ]\n\nTotal average test accuarcy: 0.8302\nTotal average test loss: 0.001582399308681488\n\nTime elapsed: 1299.3745093345642\n\n[ Train epoch: 55 ]\n\nTotal average train accuarcy: 0.6476800949568172\nTotal average train loss: 0.020603865690231322\n\n[ Test epoch: 55 ]\n\nTotal average test accuarcy: 0.8296\nTotal average test loss: 0.0015622250199317932\n\nTime elapsed: 1323.4517629146576\n\n[ Train epoch: 56 ]\n\nTotal average train accuarcy: 0.6554242455735794\nTotal average train loss: 0.02048829615354538\n\n[ Test epoch: 56 ]\n\nTotal average test accuarcy: 0.8375\nTotal average test loss: 0.001533105993270874\n\nTime elapsed: 1346.5039546489716\n\n[ Train epoch: 57 ]\n\nTotal average train accuarcy: 0.6530866122721862\nTotal average train loss: 0.02052304580450058\n\n[ Test epoch: 57 ]\n\nTotal average test accuarcy: 0.8461\nTotal average test loss: 0.0015140650749206543\n\nTime elapsed: 1370.3894591331482\n\n[ Train epoch: 58 ]\n\nTotal average train accuarcy: 0.6535157819325037\nTotal average train loss: 0.020596106820106506\n\n[ Test epoch: 58 ]\n\nTotal average test accuarcy: 0.8425\nTotal average test loss: 0.00154267817735672\n\nTime elapsed: 1394.0270404815674\n\n[ Train epoch: 59 ]\n\nTotal average train accuarcy: 0.6473278691823582\nTotal average train loss: 0.020625703308582304\n\n[ Test epoch: 59 ]\n\nTotal average test accuarcy: 0.8464\nTotal average test loss: 0.001503027355670929\n\nTime elapsed: 1416.9585328102112\n\n[ Train epoch: 60 ]\n\nTotal average train accuarcy: 0.6489300165268892\nTotal average train loss: 0.020603425285816192\n\n[ Test epoch: 60 ]\n\nTotal average test accuarcy: 0.8394\nTotal average test loss: 0.001504031801223755\n\nTime elapsed: 1441.5275483131409\n\n[ Train epoch: 61 ]\n\nTotal average train accuarcy: 0.6570577754783496\nTotal average train loss: 0.02038808176279068\n\n[ Test epoch: 61 ]\n\nTotal average test accuarcy: 0.8494\nTotal average test loss: 0.0015135855197906493\n\nTime elapsed: 1464.7680270671844\n\n[ Train epoch: 62 ]\n\nTotal average train accuarcy: 0.6562548648687455\nTotal average train loss: 0.020460887463092804\n\n[ Test epoch: 62 ]\n\nTotal average test accuarcy: 0.8534\nTotal average test loss: 0.0015022109746932984\n\nTime elapsed: 1487.7519817352295\n\n[ Train epoch: 63 ]\n\nTotal average train accuarcy: 0.6671009332321152\nTotal average train loss: 0.020237668073177336\n\n[ Test epoch: 63 ]\n\nTotal average test accuarcy: 0.8482\nTotal average test loss: 0.0015274085283279418\n\nTime elapsed: 1512.1026284694672\n\n[ Train epoch: 64 ]\n\nTotal average train accuarcy: 0.649191597419848\nTotal average train loss: 0.020611966767311096\n\n[ Test epoch: 64 ]\n\nTotal average test accuarcy: 0.8476\nTotal average test loss: 0.0015216084241867066\n\nTime elapsed: 1535.326311826706\n\n[ Train epoch: 65 ]\n\nTotal average train accuarcy: 0.6449512577109188\nTotal average train loss: 0.020584498693943024\n\n[ Test epoch: 65 ]\n\nTotal average test accuarcy: 0.8558\nTotal average test loss: 0.0014919850945472716\n\nTime elapsed: 1558.0863881111145\n\n[ Train epoch: 66 ]\n\nTotal average train accuarcy: 0.650610558190284\nTotal average train loss: 0.020497535977363587\n\n[ Test epoch: 66 ]\n\nTotal average test accuarcy: 0.8268\nTotal average test loss: 0.0015535900354385376\n\nTime elapsed: 1582.639101266861\n\n[ Train epoch: 67 ]\n\nTotal average train accuarcy: 0.6545709788890477\nTotal average train loss: 0.02038723214626312\n\n[ Test epoch: 67 ]\n\nTotal average test accuarcy: 0.8272\nTotal average test loss: 0.0016053308129310609\n\nTime elapsed: 1605.6050055027008\n\n[ Train epoch: 68 ]\n\nTotal average train accuarcy: 0.6713324560841791\nTotal average train loss: 0.02013063372373581\n\n[ Test epoch: 68 ]\n\nTotal average test accuarcy: 0.836\nTotal average test loss: 0.0015588190674781799\n\nTime elapsed: 1628.6418488025665\n\n[ Train epoch: 69 ]\n\nTotal average train accuarcy: 0.6508393293528831\nTotal average train loss: 0.02053962415933609\n\n[ Test epoch: 69 ]\n\nTotal average test accuarcy: 0.8517\nTotal average test loss: 0.0015027891159057618\n\nTime elapsed: 1653.114203453064\n\n[ Train epoch: 70 ]\n\nTotal average train accuarcy: 0.6653758867996021\nTotal average train loss: 0.02013323742866516\n\n[ Test epoch: 70 ]\n\nTotal average test accuarcy: 0.8518\nTotal average test loss: 0.0014944103479385376\n\nTime elapsed: 1677.471534729004\n\n[ Train epoch: 71 ]\n\nTotal average train accuarcy: 0.6674931786958511\nTotal average train loss: 0.020090716772079468\n\n[ Test epoch: 71 ]\n\nTotal average test accuarcy: 0.8316\nTotal average test loss: 0.0015778451800346374\n\nTime elapsed: 1700.5883750915527\n\n[ Train epoch: 72 ]\n\nTotal average train accuarcy: 0.6602952829731739\nTotal average train loss: 0.02032134449481964\n\n[ Test epoch: 72 ]\n\nTotal average test accuarcy: 0.8505\nTotal average test loss: 0.0015004892468452454\n\nTime elapsed: 1723.2802033424377\n\n[ Train epoch: 73 ]\n\nTotal average train accuarcy: 0.6730952198262214\nTotal average train loss: 0.02003885121822357\n\n[ Test epoch: 73 ]\n\nTotal average test accuarcy: 0.8499\nTotal average test loss: 0.001536833381652832\n\nTime elapsed: 1747.7872817516327\n\n[ Train epoch: 74 ]\n\nTotal average train accuarcy: 0.657015749135229\nTotal average train loss: 0.020392252810001375\n\n[ Test epoch: 74 ]\n\nTotal average test accuarcy: 0.8501\nTotal average test loss: 0.0015157842159271241\n\nTime elapsed: 1771.1200892925262\n\n[ Train epoch: 75 ]\n\nTotal average train accuarcy: 0.6608721558063598\nTotal average train loss: 0.020308955879211426\n\n[ Test epoch: 75 ]\n\nTotal average test accuarcy: 0.8531\nTotal average test loss: 0.0015221292972564698\n\nTime elapsed: 1794.1071090698242\n\n[ Train epoch: 76 ]\n\nTotal average train accuarcy: 0.6627271591140251\nTotal average train loss: 0.020236017146110535\n\n[ Test epoch: 76 ]\n\nTotal average test accuarcy: 0.8321\nTotal average test loss: 0.0015978614568710327\n\nTime elapsed: 1818.0954253673553\n\n[ Train epoch: 77 ]\n\nTotal average train accuarcy: 0.6683994688443445\nTotal average train loss: 0.020111627831459044\n\n[ Test epoch: 77 ]\n\nTotal average test accuarcy: 0.8514\nTotal average test loss: 0.0015326756715774536\n\nTime elapsed: 1841.0083768367767\n\n[ Train epoch: 78 ]\n\nTotal average train accuarcy: 0.6635101728703432\nTotal average train loss: 0.02023960550546646\n\n[ Test epoch: 78 ]\n\nTotal average test accuarcy: 0.8431\nTotal average test loss: 0.0015662220120429993\n\nTime elapsed: 1865.0812804698944\n\n[ Train epoch: 79 ]\n\nTotal average train accuarcy: 0.6569171625304713\nTotal average train loss: 0.02038899701833725\n\n[ Test epoch: 79 ]\n\nTotal average test accuarcy: 0.8511\nTotal average test loss: 0.0015393934369087219\n\nTime elapsed: 1888.6556191444397\n\n[ Train epoch: 80 ]\n\nTotal average train accuarcy: 0.6587958512997705\nTotal average train loss: 0.020310578277111052\n\n[ Test epoch: 80 ]\n\nTotal average test accuarcy: 0.8259\nTotal average test loss: 0.001592167615890503\n\nTime elapsed: 1911.794942855835\n\n[ Train epoch: 81 ]\n\nTotal average train accuarcy: 0.6652376143857259\nTotal average train loss: 0.020197321634292602\n\n[ Test epoch: 81 ]\n\nTotal average test accuarcy: 0.8492\nTotal average test loss: 0.0015370748519897462\n\nTime elapsed: 1936.0164580345154\n\n[ Train epoch: 82 ]\n\nTotal average train accuarcy: 0.6745537787940952\nTotal average train loss: 0.019985504782199858\n\n[ Test epoch: 82 ]\n\nTotal average test accuarcy: 0.8503\nTotal average test loss: 0.0015154361963272095\n\nTime elapsed: 1959.514901638031\n\n[ Train epoch: 83 ]\n\nTotal average train accuarcy: 0.6622026467541201\nTotal average train loss: 0.020262489974498747\n\n[ Test epoch: 83 ]\n\nTotal average test accuarcy: 0.8509\nTotal average test loss: 0.0015354988932609558\n\nTime elapsed: 1983.5477893352509\n\n[ Train epoch: 84 ]\n\nTotal average train accuarcy: 0.6693364600295566\nTotal average train loss: 0.02011499007463455\n\n[ Test epoch: 84 ]\n\nTotal average test accuarcy: 0.8543\nTotal average test loss: 0.001504991888999939\n\nTime elapsed: 2006.4985909461975\n\n[ Train epoch: 85 ]\n\nTotal average train accuarcy: 0.661442286414354\nTotal average train loss: 0.020223860878944396\n\n[ Test epoch: 85 ]\n\nTotal average test accuarcy: 0.8456\nTotal average test loss: 0.001537669336795807\n\nTime elapsed: 2030.6876547336578\n\n[ Train epoch: 86 ]\n\nTotal average train accuarcy: 0.6741454827397096\nTotal average train loss: 0.01992325567483902\n\n[ Test epoch: 86 ]\n\nTotal average test accuarcy: 0.8441\nTotal average test loss: 0.0015046706914901733\n\nTime elapsed: 2054.329002380371\n\n[ Train epoch: 87 ]\n\nTotal average train accuarcy: 0.6595046574444459\nTotal average train loss: 0.020298575253486634\n\n[ Test epoch: 87 ]\n\nTotal average test accuarcy: 0.8438\nTotal average test loss: 0.0015296623826026917\n\nTime elapsed: 2077.2834265232086\n\n[ Train epoch: 88 ]\n\nTotal average train accuarcy: 0.6692943857830053\nTotal average train loss: 0.020159683308601378\n\n[ Test epoch: 88 ]\n\nTotal average test accuarcy: 0.85\nTotal average test loss: 0.001544061005115509\n\nTime elapsed: 2101.3545639514923\n\n[ Train epoch: 89 ]\n\nTotal average train accuarcy: 0.6724356363173128\nTotal average train loss: 0.020013798391819\n\n[ Test epoch: 89 ]\n\nTotal average test accuarcy: 0.8405\nTotal average test loss: 0.001557209050655365\n\nTime elapsed: 2124.8463604450226\n\n[ Train epoch: 90 ]\n\nTotal average train accuarcy: 0.673353169806702\nTotal average train loss: 0.019984386212825774\n\n[ Test epoch: 90 ]\n\nTotal average test accuarcy: 0.8406\nTotal average test loss: 0.0015668355464935303\n\nTime elapsed: 2147.5804948806763\n\n[ Train epoch: 91 ]\n\nTotal average train accuarcy: 0.667425635866638\nTotal average train loss: 0.020134174811840058\n\n[ Test epoch: 91 ]\n\nTotal average test accuarcy: 0.837\nTotal average test loss: 0.001556403160095215\n\nTime elapsed: 2171.933424949646\n\n[ Train epoch: 92 ]\n\nTotal average train accuarcy: 0.6745272219780754\nTotal average train loss: 0.020013518679141997\n\n[ Test epoch: 92 ]\n\nTotal average test accuarcy: 0.8509\nTotal average test loss: 0.0014900675535202026\n\nTime elapsed: 2195.310397863388\n\n[ Train epoch: 93 ]\n\nTotal average train accuarcy: 0.6748465527030115\nTotal average train loss: 0.019960587294101714\n\n[ Test epoch: 93 ]\n\nTotal average test accuarcy: 0.8605\nTotal average test loss: 0.0014561468124389648\n\nTime elapsed: 2218.0989775657654\n\n[ Train epoch: 94 ]\n\nTotal average train accuarcy: 0.6699782859949002\nTotal average train loss: 0.02009124715566635\n\n[ Test epoch: 94 ]\n\nTotal average test accuarcy: 0.856\nTotal average test loss: 0.0015322379112243652\n\nTime elapsed: 2242.9267575740814\n\n[ Train epoch: 95 ]\n\nTotal average train accuarcy: 0.6642678675481952\nTotal average train loss: 0.020273623015880586\n\n[ Test epoch: 95 ]\n\nTotal average test accuarcy: 0.8368\nTotal average test loss: 0.0015667991042137145\n\nTime elapsed: 2265.8955590724945\n\n[ Train epoch: 96 ]\n\nTotal average train accuarcy: 0.6742483494106348\nTotal average train loss: 0.01997948880672455\n\n[ Test epoch: 96 ]\n\nTotal average test accuarcy: 0.839\nTotal average test loss: 0.0015539496541023255\n\nTime elapsed: 2289.394166946411\n\n[ Train epoch: 97 ]\n\nTotal average train accuarcy: 0.6721176144763552\nTotal average train loss: 0.020045164580345155\n\n[ Test epoch: 97 ]\n\nTotal average test accuarcy: 0.8563\nTotal average test loss: 0.0015115530610084534\n\nTime elapsed: 2312.9769065380096\n\n[ Train epoch: 98 ]\n\nTotal average train accuarcy: 0.6741951891173844\nTotal average train loss: 0.01998442810535431\n\n[ Test epoch: 98 ]\n\nTotal average test accuarcy: 0.8528\nTotal average test loss: 0.001533539307117462\n\nTime elapsed: 2337.3135533332825\n\n[ Train epoch: 99 ]\n\nTotal average train accuarcy: 0.6591938217845605\nTotal average train loss: 0.020291978447437287\n\n[ Test epoch: 99 ]\n\nTotal average test accuarcy: 0.8499\nTotal average test loss: 0.0015321735858917235\n\nTime elapsed: 2360.62539601326\n\n[ Train epoch: 100 ]\n\nTotal average train accuarcy: 0.6708903658320167\nTotal average train loss: 0.020115718598365785\n\n[ Test epoch: 100 ]\n\nTotal average test accuarcy: 0.871\nTotal average test loss: 0.0014704183220863342\n\nTime elapsed: 2384.5192749500275\n\n[ Train epoch: 101 ]\n\nTotal average train accuarcy: 0.6870717819679809\nTotal average train loss: 0.01967419306755066\n\n[ Test epoch: 101 ]\n\nTotal average test accuarcy: 0.8673\nTotal average test loss: 0.00150180481672287\n\nTime elapsed: 2408.2609479427338\n\n[ Train epoch: 102 ]\n\nTotal average train accuarcy: 0.6833517984427238\nTotal average train loss: 0.019748214597702027\n\n[ Test epoch: 102 ]\n\nTotal average test accuarcy: 0.8725\nTotal average test loss: 0.0014563292860984803\n\nTime elapsed: 2431.343215942383\n\n[ Train epoch: 103 ]\n\nTotal average train accuarcy: 0.6770632039364651\nTotal average train loss: 0.019808145067691803\n\n[ Test epoch: 103 ]\n\nTotal average test accuarcy: 0.8735\nTotal average test loss: 0.0014367040872573851\n\nTime elapsed: 2454.967389822006\n\n[ Train epoch: 104 ]\n\nTotal average train accuarcy: 0.6955464239287673\nTotal average train loss: 0.01945842031955719\n\n[ Test epoch: 104 ]\n\nTotal average test accuarcy: 0.8735\nTotal average test loss: 0.0014579280734062195\n\nTime elapsed: 2478.99577832222\n\n[ Train epoch: 105 ]\n\nTotal average train accuarcy: 0.6886937869065072\nTotal average train loss: 0.019723991057872772\n\n[ Test epoch: 105 ]\n\nTotal average test accuarcy: 0.8721\nTotal average test loss: 0.0015098237752914428\n\nTime elapsed: 2501.714146375656\n\n[ Train epoch: 106 ]\n\nTotal average train accuarcy: 0.7109396494957417\nTotal average train loss: 0.019159195625782013\n\n[ Test epoch: 106 ]\n\nTotal average test accuarcy: 0.8733\nTotal average test loss: 0.0014743980288505554\n\nTime elapsed: 2525.5036725997925\n\n[ Train epoch: 107 ]\n\nTotal average train accuarcy: 0.6837056477433372\nTotal average train loss: 0.019664777867794036\n\n[ Test epoch: 107 ]\n\nTotal average test accuarcy: 0.8751\nTotal average test loss: 0.0014438743591308593\n\nTime elapsed: 2549.514416694641\n\n[ Train epoch: 108 ]\n\nTotal average train accuarcy: 0.683656069965643\nTotal average train loss: 0.019719755477905273\n\n[ Test epoch: 108 ]\n\nTotal average test accuarcy: 0.8764\nTotal average test loss: 0.0014574568510055542\n\nTime elapsed: 2571.8216094970703\n\n[ Train epoch: 109 ]\n\nTotal average train accuarcy: 0.7115540845754932\nTotal average train loss: 0.01916490421295166\n\n[ Test epoch: 109 ]\n\nTotal average test accuarcy: 0.8757\nTotal average test loss: 0.0014516868352890014\n\nTime elapsed: 2595.884094953537\n\n[ Train epoch: 110 ]\n\nTotal average train accuarcy: 0.6978657782738457\nTotal average train loss: 0.019361910939216614\n\n[ Test epoch: 110 ]\n\nTotal average test accuarcy: 0.875\nTotal average test loss: 0.001464659547805786\n\nTime elapsed: 2619.827065229416\n\n[ Train epoch: 111 ]\n\nTotal average train accuarcy: 0.699752729335968\nTotal average train loss: 0.019343871002197265\n\n[ Test epoch: 111 ]\n\nTotal average test accuarcy: 0.8758\nTotal average test loss: 0.001458440101146698\n\nTime elapsed: 2643.820206642151\n\n[ Train epoch: 112 ]\n\nTotal average train accuarcy: 0.7037162703985702\nTotal average train loss: 0.019326223418712617\n\n[ Test epoch: 112 ]\n\nTotal average test accuarcy: 0.8781\nTotal average test loss: 0.001418934953212738\n\nTime elapsed: 2666.6336300373077\n\n[ Train epoch: 113 ]\n\nTotal average train accuarcy: 0.6935964526040567\nTotal average train loss: 0.019544030652046202\n\n[ Test epoch: 113 ]\n\nTotal average test accuarcy: 0.8738\nTotal average test loss: 0.0014625779747962952\n\nTime elapsed: 2690.412897825241\n\n[ Train epoch: 114 ]\n\nTotal average train accuarcy: 0.6949416316350789\nTotal average train loss: 0.019469606363773345\n\n[ Test epoch: 114 ]\n\nTotal average test accuarcy: 0.8765\nTotal average test loss: 0.001451520526409149\n\nTime elapsed: 2714.4884326457977\n\n[ Train epoch: 115 ]\n\nTotal average train accuarcy: 0.6943290160396336\nTotal average train loss: 0.019442819380760194\n\n[ Test epoch: 115 ]\n\nTotal average test accuarcy: 0.8755\nTotal average test loss: 0.0014391316771507263\n\nTime elapsed: 2737.316047668457\n\n[ Train epoch: 116 ]\n\nTotal average train accuarcy: 0.6966175678122688\nTotal average train loss: 0.01946674336910248\n\n[ Test epoch: 116 ]\n\nTotal average test accuarcy: 0.8754\nTotal average test loss: 0.001471103012561798\n\nTime elapsed: 2760.9446198940277\n\n[ Train epoch: 117 ]\n\nTotal average train accuarcy: 0.7038412554893999\nTotal average train loss: 0.01930497596025467\n\n[ Test epoch: 117 ]\n\nTotal average test accuarcy: 0.8762\nTotal average test loss: 0.0014532615423202514\n\nTime elapsed: 2784.91717171669\n\n[ Train epoch: 118 ]\n\nTotal average train accuarcy: 0.7083925262865292\nTotal average train loss: 0.019173889870643616\n\n[ Test epoch: 118 ]\n\nTotal average test accuarcy: 0.8721\nTotal average test loss: 0.0014873150944709778\n\nTime elapsed: 2807.8077301979065\n\n[ Train epoch: 119 ]\n\nTotal average train accuarcy: 0.6936875786017938\nTotal average train loss: 0.019500450625419618\n\n[ Test epoch: 119 ]\n\nTotal average test accuarcy: 0.8757\nTotal average test loss: 0.0014461580991744995\n\nTime elapsed: 2831.5552291870117\n\n[ Train epoch: 120 ]\n\nTotal average train accuarcy: 0.6917797667093762\nTotal average train loss: 0.019462878618240358\n\n[ Test epoch: 120 ]\n\nTotal average test accuarcy: 0.8748\nTotal average test loss: 0.0014307427406311036\n\nTime elapsed: 2854.8947207927704\n\n[ Train epoch: 121 ]\n\nTotal average train accuarcy: 0.6912413568879913\nTotal average train loss: 0.01949784623384476\n\n[ Test epoch: 121 ]\n\nTotal average test accuarcy: 0.8728\nTotal average test loss: 0.0014613384366035462\n\nTime elapsed: 2877.87416100502\n\n[ Train epoch: 122 ]\n\nTotal average train accuarcy: 0.6863646959641979\nTotal average train loss: 0.01965288123369217\n\n[ Test epoch: 122 ]\n\nTotal average test accuarcy: 0.8753\nTotal average test loss: 0.0014497747302055358\n\nTime elapsed: 2902.5469620227814\n\n[ Train epoch: 123 ]\n\nTotal average train accuarcy: 0.694072109168347\nTotal average train loss: 0.01950108766078949\n\n[ Test epoch: 123 ]\n\nTotal average test accuarcy: 0.874\nTotal average test loss: 0.0014549902677536012\n\nTime elapsed: 2925.0530812740326\n\n[ Train epoch: 124 ]\n\nTotal average train accuarcy: 0.7030134163423218\nTotal average train loss: 0.019297185835838317\n\n[ Test epoch: 124 ]\n\nTotal average test accuarcy: 0.8771\nTotal average test loss: 0.0014436374068260193\n\nTime elapsed: 2948.4431750774384\n\n[ Train epoch: 125 ]\n\nTotal average train accuarcy: 0.6891349307102125\nTotal average train loss: 0.019536024796962738\n\n[ Test epoch: 125 ]\n\nTotal average test accuarcy: 0.8742\nTotal average test loss: 0.0014699203252792358\n\nTime elapsed: 2972.62797999382\n\n[ Train epoch: 126 ]\n\nTotal average train accuarcy: 0.7095015954263503\nTotal average train loss: 0.01910992148399353\n\n[ Test epoch: 126 ]\n\nTotal average test accuarcy: 0.8747\nTotal average test loss: 0.0014548576951026917\n\nTime elapsed: 2996.41117978096\n\n[ Train epoch: 127 ]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a1f915dcdbf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTime elapsed:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-a1f915dcdbf1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}