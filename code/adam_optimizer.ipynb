{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdluQj1WgsoQ",
        "outputId": "bba66c36-8d02-4cb7-8a22-827c4068b97b"
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torch import Tensor\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.models import resnet\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torchvision.models.resnet import resnet18\n",
        "\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "\n",
        "import time\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 10,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        \n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
        "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "     \n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "변경사항 batch_size=1000\n",
        "\"\"\"\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True, num_workers=2)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "mixup_alpha = 1.0\n",
        "\n",
        "def mixup_data(x, y):\n",
        "    lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "    def forward(self, y, targets, smoothing=0.1):\n",
        "        confidence = 1. - smoothing\n",
        "        log_probs = F.log_softmax(y, dim=-1) # 예측 확률 계산\n",
        "        true_probs = torch.zeros_like(log_probs)\n",
        "        true_probs.fill_(smoothing / (y.shape[1] - 1))\n",
        "        true_probs.scatter_(1, targets.data.unsqueeze(1), confidence) # 정답 인덱스의 정답 확률을 confidence로 변경\n",
        "        return torch.mean(torch.sum(true_probs * -log_probs, dim=-1)) # negative log likelihood\n",
        "\n",
        "    \n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "net = resnet18()\n",
        "net = net.to(device)\n",
        "\n",
        "\"\"\"\n",
        "변경사항 learning_rate=0.001\n",
        "\"\"\"\n",
        "learning_rate=0.001\n",
        "\n",
        "# learning_rate = 0.1\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0002)\n",
        "\n",
        "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        \n",
        "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        current_correct = (lam * predicted.eq(targets_a).sum().item() + (1 - lam) * predicted.eq(targets_b).sum().item())\n",
        "        correct += current_correct\n",
        "\n",
        "        \n",
        "\n",
        "    print('\\nTotal average train accuarcy:', correct / total)\n",
        "    print('Total average train loss:', train_loss / total)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('\\nTotal average test accuarcy:', correct / total)\n",
        "    print('Total average test loss:', loss / total)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 30:\n",
        "        lr /= 10\n",
        "    if epoch >= 60:\n",
        "        lr /= 10\n",
        "    if epoch >= 90:\n",
        "        lr /= 10\n",
        "    \n",
        "        \n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(0, 100):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    print('\\nTime elapsed:', time.time() - start_time)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "[ Train epoch: 0 ]\n",
            "\n",
            "Total average train accuarcy: 0.29776416118515364\n",
            "Total average train loss: 0.0030309335374832155\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "\n",
            "Total average test accuarcy: 0.4353\n",
            "Total average test loss: 0.0024439144372940063\n",
            "\n",
            "Time elapsed: 17.629265785217285\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Total average train accuarcy: 0.3852017318199965\n",
            "Total average train loss: 0.002606799054145813\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Total average test accuarcy: 0.4681\n",
            "Total average test loss: 0.0023847259521484377\n",
            "\n",
            "Time elapsed: 34.669553995132446\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Total average train accuarcy: 0.4084780420872712\n",
            "Total average train loss: 0.002572467384338379\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Total average test accuarcy: 0.5596\n",
            "Total average test loss: 0.0022087003231048585\n",
            "\n",
            "Time elapsed: 51.859309911727905\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Total average train accuarcy: 0.4437508904698196\n",
            "Total average train loss: 0.002510028748512268\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Total average test accuarcy: 0.595\n",
            "Total average test loss: 0.0021137641668319703\n",
            "\n",
            "Time elapsed: 69.25766777992249\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Total average train accuarcy: 0.45513311922016847\n",
            "Total average train loss: 0.0024912059879302977\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Total average test accuarcy: 0.6063\n",
            "Total average test loss: 0.0020775752544403077\n",
            "\n",
            "Time elapsed: 87.13933753967285\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Total average train accuarcy: 0.49104300833202846\n",
            "Total average train loss: 0.002408899230957031\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Total average test accuarcy: 0.6255\n",
            "Total average test loss: 0.00199989116191864\n",
            "\n",
            "Time elapsed: 105.22990942001343\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Total average train accuarcy: 0.49463397303213236\n",
            "Total average train loss: 0.0024107903909683227\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Total average test accuarcy: 0.4918\n",
            "Total average test loss: 0.0023584343671798707\n",
            "\n",
            "Time elapsed: 122.97726702690125\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Total average train accuarcy: 0.5352675330410545\n",
            "Total average train loss: 0.0023243149065971373\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Total average test accuarcy: 0.5887\n",
            "Total average test loss: 0.00210758011341095\n",
            "\n",
            "Time elapsed: 140.61350345611572\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Total average train accuarcy: 0.5288003267859549\n",
            "Total average train loss: 0.0023372360825538634\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Total average test accuarcy: 0.5322\n",
            "Total average test loss: 0.002216683101654053\n",
            "\n",
            "Time elapsed: 158.32827711105347\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Total average train accuarcy: 0.5348132825169278\n",
            "Total average train loss: 0.0023193959498405458\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Total average test accuarcy: 0.5998\n",
            "Total average test loss: 0.002097408556938171\n",
            "\n",
            "Time elapsed: 176.0350091457367\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Total average train accuarcy: 0.4941603703602757\n",
            "Total average train loss: 0.002410617022514343\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Total average test accuarcy: 0.6052\n",
            "Total average test loss: 0.0020908453941345215\n",
            "\n",
            "Time elapsed: 193.88548755645752\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "\n",
            "Total average train accuarcy: 0.5283618928842336\n",
            "Total average train loss: 0.0023388168096542357\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "\n",
            "Total average test accuarcy: 0.7071\n",
            "Total average test loss: 0.0018571306943893434\n",
            "\n",
            "Time elapsed: 211.74649095535278\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "\n",
            "Total average train accuarcy: 0.5819494711779719\n",
            "Total average train loss: 0.002221716408729553\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "\n",
            "Total average test accuarcy: 0.6771\n",
            "Total average test loss: 0.0019030797362327575\n",
            "\n",
            "Time elapsed: 229.4687135219574\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "\n",
            "Total average train accuarcy: 0.5793132228804917\n",
            "Total average train loss: 0.00223265282869339\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "\n",
            "Total average test accuarcy: 0.651\n",
            "Total average test loss: 0.0019528909683227539\n",
            "\n",
            "Time elapsed: 247.23370361328125\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "\n",
            "Total average train accuarcy: 0.5284935679320353\n",
            "Total average train loss: 0.0023464021468162536\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "\n",
            "Total average test accuarcy: 0.6344\n",
            "Total average test loss: 0.0020124387979507446\n",
            "\n",
            "Time elapsed: 264.99778175354004\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "\n",
            "Total average train accuarcy: 0.5634127064649265\n",
            "Total average train loss: 0.002259859392642975\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "\n",
            "Total average test accuarcy: 0.7107\n",
            "Total average test loss: 0.0018482916474342346\n",
            "\n",
            "Time elapsed: 282.7264726161957\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "\n",
            "Total average train accuarcy: 0.5755073440024341\n",
            "Total average train loss: 0.0022446250462532045\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "\n",
            "Total average test accuarcy: 0.7313\n",
            "Total average test loss: 0.0018063236951828003\n",
            "\n",
            "Time elapsed: 300.4578402042389\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "\n",
            "Total average train accuarcy: 0.5529030345728794\n",
            "Total average train loss: 0.0022960851860046386\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "\n",
            "Total average test accuarcy: 0.6523\n",
            "Total average test loss: 0.0019634986639022827\n",
            "\n",
            "Time elapsed: 318.2730219364166\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "\n",
            "Total average train accuarcy: 0.5735610736118125\n",
            "Total average train loss: 0.002247871298789978\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "\n",
            "Total average test accuarcy: 0.6788\n",
            "Total average test loss: 0.0019533982276916505\n",
            "\n",
            "Time elapsed: 336.09480381011963\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "\n",
            "Total average train accuarcy: 0.5847716139376454\n",
            "Total average train loss: 0.0022265985465049743\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "\n",
            "Total average test accuarcy: 0.6287\n",
            "Total average test loss: 0.001998132634162903\n",
            "\n",
            "Time elapsed: 353.79083776474\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "\n",
            "Total average train accuarcy: 0.5595838111953745\n",
            "Total average train loss: 0.002278658437728882\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "\n",
            "Total average test accuarcy: 0.7185\n",
            "Total average test loss: 0.0018420273900032044\n",
            "\n",
            "Time elapsed: 371.4962360858917\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "\n",
            "Total average train accuarcy: 0.569938469145189\n",
            "Total average train loss: 0.002245125677585602\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "\n",
            "Total average test accuarcy: 0.7418\n",
            "Total average test loss: 0.0017802198767662048\n",
            "\n",
            "Time elapsed: 389.29460525512695\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "\n",
            "Total average train accuarcy: 0.554505659721728\n",
            "Total average train loss: 0.0022741967296600342\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "\n",
            "Total average test accuarcy: 0.7472\n",
            "Total average test loss: 0.0017405224800109862\n",
            "\n",
            "Time elapsed: 407.0723571777344\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "\n",
            "Total average train accuarcy: 0.60470062266832\n",
            "Total average train loss: 0.002169326615333557\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "\n",
            "Total average test accuarcy: 0.7227\n",
            "Total average test loss: 0.0017881025195121765\n",
            "\n",
            "Time elapsed: 424.78629875183105\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "\n",
            "Total average train accuarcy: 0.587237036633217\n",
            "Total average train loss: 0.002211137204170227\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "\n",
            "Total average test accuarcy: 0.7153\n",
            "Total average test loss: 0.0018207596778869628\n",
            "\n",
            "Time elapsed: 442.51710200309753\n",
            "\n",
            "[ Train epoch: 25 ]\n",
            "\n",
            "Total average train accuarcy: 0.5808613635641351\n",
            "Total average train loss: 0.0022118690061569213\n",
            "\n",
            "[ Test epoch: 25 ]\n",
            "\n",
            "Total average test accuarcy: 0.7446\n",
            "Total average test loss: 0.0017867121696472168\n",
            "\n",
            "Time elapsed: 460.29418683052063\n",
            "\n",
            "[ Train epoch: 26 ]\n",
            "\n",
            "Total average train accuarcy: 0.6305373272343691\n",
            "Total average train loss: 0.0021182662534713747\n",
            "\n",
            "[ Test epoch: 26 ]\n",
            "\n",
            "Total average test accuarcy: 0.7204\n",
            "Total average test loss: 0.0018091115713119506\n",
            "\n",
            "Time elapsed: 477.9644076824188\n",
            "\n",
            "[ Train epoch: 27 ]\n",
            "\n",
            "Total average train accuarcy: 0.623245539915539\n",
            "Total average train loss: 0.002126200742721558\n",
            "\n",
            "[ Test epoch: 27 ]\n",
            "\n",
            "Total average test accuarcy: 0.7443\n",
            "Total average test loss: 0.0017546409249305725\n",
            "\n",
            "Time elapsed: 495.73054814338684\n",
            "\n",
            "[ Train epoch: 28 ]\n",
            "\n",
            "Total average train accuarcy: 0.6232443609688111\n",
            "Total average train loss: 0.002136826136112213\n",
            "\n",
            "[ Test epoch: 28 ]\n",
            "\n",
            "Total average test accuarcy: 0.7348\n",
            "Total average test loss: 0.0017911721587181091\n",
            "\n",
            "Time elapsed: 513.2748448848724\n",
            "\n",
            "[ Train epoch: 29 ]\n",
            "\n",
            "Total average train accuarcy: 0.5925010465132926\n",
            "Total average train loss: 0.002196809945106506\n",
            "\n",
            "[ Test epoch: 29 ]\n",
            "\n",
            "Total average test accuarcy: 0.7004\n",
            "Total average test loss: 0.0018822303533554078\n",
            "\n",
            "Time elapsed: 530.755405664444\n",
            "\n",
            "[ Train epoch: 30 ]\n",
            "\n",
            "Total average train accuarcy: 0.588308502994159\n",
            "Total average train loss: 0.0021695712184906005\n",
            "\n",
            "[ Test epoch: 30 ]\n",
            "\n",
            "Total average test accuarcy: 0.8\n",
            "Total average test loss: 0.0016468575954437256\n",
            "\n",
            "Time elapsed: 548.2324092388153\n",
            "\n",
            "[ Train epoch: 31 ]\n",
            "\n",
            "Total average train accuarcy: 0.615005029281631\n",
            "Total average train loss: 0.0021243502688407896\n",
            "\n",
            "[ Test epoch: 31 ]\n",
            "\n",
            "Total average test accuarcy: 0.8109\n",
            "Total average test loss: 0.001594580352306366\n",
            "\n",
            "Time elapsed: 565.7212903499603\n",
            "\n",
            "[ Train epoch: 32 ]\n",
            "\n",
            "Total average train accuarcy: 0.5942805465281007\n",
            "Total average train loss: 0.002185333833694458\n",
            "\n",
            "[ Test epoch: 32 ]\n",
            "\n",
            "Total average test accuarcy: 0.7993\n",
            "Total average test loss: 0.0016639265537261962\n",
            "\n",
            "Time elapsed: 583.1440315246582\n",
            "\n",
            "[ Train epoch: 33 ]\n",
            "\n",
            "Total average train accuarcy: 0.6244005157964342\n",
            "Total average train loss: 0.0021005857396125794\n",
            "\n",
            "[ Test epoch: 33 ]\n",
            "\n",
            "Total average test accuarcy: 0.8122\n",
            "Total average test loss: 0.0016113593578338623\n",
            "\n",
            "Time elapsed: 600.3851482868195\n",
            "\n",
            "[ Train epoch: 34 ]\n",
            "\n",
            "Total average train accuarcy: 0.6256525347597222\n",
            "Total average train loss: 0.0021146881580352784\n",
            "\n",
            "[ Test epoch: 34 ]\n",
            "\n",
            "Total average test accuarcy: 0.8097\n",
            "Total average test loss: 0.001618182945251465\n",
            "\n",
            "Time elapsed: 617.6888031959534\n",
            "\n",
            "[ Train epoch: 35 ]\n",
            "\n",
            "Total average train accuarcy: 0.6372858702954104\n",
            "Total average train loss: 0.0020799786233901977\n",
            "\n",
            "[ Test epoch: 35 ]\n",
            "\n",
            "Total average test accuarcy: 0.8074\n",
            "Total average test loss: 0.0016259152054786683\n",
            "\n",
            "Time elapsed: 635.0574963092804\n",
            "\n",
            "[ Train epoch: 36 ]\n",
            "\n",
            "Total average train accuarcy: 0.6429613850784498\n",
            "Total average train loss: 0.0020665098094940185\n",
            "\n",
            "[ Test epoch: 36 ]\n",
            "\n",
            "Total average test accuarcy: 0.8106\n",
            "Total average test loss: 0.001619344413280487\n",
            "\n",
            "Time elapsed: 652.250109910965\n",
            "\n",
            "[ Train epoch: 37 ]\n",
            "\n",
            "Total average train accuarcy: 0.6384363953896782\n",
            "Total average train loss: 0.0020787995171546937\n",
            "\n",
            "[ Test epoch: 37 ]\n",
            "\n",
            "Total average test accuarcy: 0.8161\n",
            "Total average test loss: 0.0015919481992721558\n",
            "\n",
            "Time elapsed: 669.4233396053314\n",
            "\n",
            "[ Train epoch: 38 ]\n",
            "\n",
            "Total average train accuarcy: 0.6340356390652643\n",
            "Total average train loss: 0.00208688982963562\n",
            "\n",
            "[ Test epoch: 38 ]\n",
            "\n",
            "Total average test accuarcy: 0.8183\n",
            "Total average test loss: 0.0015845421195030212\n",
            "\n",
            "Time elapsed: 686.7131502628326\n",
            "\n",
            "[ Train epoch: 39 ]\n",
            "\n",
            "Total average train accuarcy: 0.6617690492186694\n",
            "Total average train loss: 0.0020262993597984316\n",
            "\n",
            "[ Test epoch: 39 ]\n",
            "\n",
            "Total average test accuarcy: 0.8167\n",
            "Total average test loss: 0.001587281322479248\n",
            "\n",
            "Time elapsed: 703.9030137062073\n",
            "\n",
            "[ Train epoch: 40 ]\n",
            "\n",
            "Total average train accuarcy: 0.6344164962668277\n",
            "Total average train loss: 0.0021009669327735903\n",
            "\n",
            "[ Test epoch: 40 ]\n",
            "\n",
            "Total average test accuarcy: 0.8186\n",
            "Total average test loss: 0.0015810457110404968\n",
            "\n",
            "Time elapsed: 721.0631766319275\n",
            "\n",
            "[ Train epoch: 41 ]\n",
            "\n",
            "Total average train accuarcy: 0.6698741745495276\n",
            "Total average train loss: 0.002006256768703461\n",
            "\n",
            "[ Test epoch: 41 ]\n",
            "\n",
            "Total average test accuarcy: 0.8245\n",
            "Total average test loss: 0.00156566801071167\n",
            "\n",
            "Time elapsed: 738.2237501144409\n",
            "\n",
            "[ Train epoch: 42 ]\n",
            "\n",
            "Total average train accuarcy: 0.6356423996150272\n",
            "Total average train loss: 0.0020900708985328673\n",
            "\n",
            "[ Test epoch: 42 ]\n",
            "\n",
            "Total average test accuarcy: 0.8201\n",
            "Total average test loss: 0.0016074145674705505\n",
            "\n",
            "Time elapsed: 755.4551336765289\n",
            "\n",
            "[ Train epoch: 43 ]\n",
            "\n",
            "Total average train accuarcy: 0.6211564635178971\n",
            "Total average train loss: 0.002138440818786621\n",
            "\n",
            "[ Test epoch: 43 ]\n",
            "\n",
            "Total average test accuarcy: 0.8176\n",
            "Total average test loss: 0.0016049646258354186\n",
            "\n",
            "Time elapsed: 772.6139183044434\n",
            "\n",
            "[ Train epoch: 44 ]\n",
            "\n",
            "Total average train accuarcy: 0.6414119889916942\n",
            "Total average train loss: 0.0020586864495277407\n",
            "\n",
            "[ Test epoch: 44 ]\n",
            "\n",
            "Total average test accuarcy: 0.8215\n",
            "Total average test loss: 0.0015816955685615539\n",
            "\n",
            "Time elapsed: 789.792308807373\n",
            "\n",
            "[ Train epoch: 45 ]\n",
            "\n",
            "Total average train accuarcy: 0.6406221796669388\n",
            "Total average train loss: 0.0020715778279304506\n",
            "\n",
            "[ Test epoch: 45 ]\n",
            "\n",
            "Total average test accuarcy: 0.8181\n",
            "Total average test loss: 0.0016004832863807678\n",
            "\n",
            "Time elapsed: 806.9965765476227\n",
            "\n",
            "[ Train epoch: 46 ]\n",
            "\n",
            "Total average train accuarcy: 0.6398968175020737\n",
            "Total average train loss: 0.002066880702972412\n",
            "\n",
            "[ Test epoch: 46 ]\n",
            "\n",
            "Total average test accuarcy: 0.8228\n",
            "Total average test loss: 0.0015753373980522155\n",
            "\n",
            "Time elapsed: 824.3069729804993\n",
            "\n",
            "[ Train epoch: 47 ]\n",
            "\n",
            "Total average train accuarcy: 0.6445426760919188\n",
            "Total average train loss: 0.0020608207941055297\n",
            "\n",
            "[ Test epoch: 47 ]\n",
            "\n",
            "Total average test accuarcy: 0.8262\n",
            "Total average test loss: 0.0015726983070373534\n",
            "\n",
            "Time elapsed: 841.5740888118744\n",
            "\n",
            "[ Train epoch: 48 ]\n",
            "\n",
            "Total average train accuarcy: 0.645803300226639\n",
            "Total average train loss: 0.0020574160981178284\n",
            "\n",
            "[ Test epoch: 48 ]\n",
            "\n",
            "Total average test accuarcy: 0.8181\n",
            "Total average test loss: 0.0016035950183868409\n",
            "\n",
            "Time elapsed: 858.8732154369354\n",
            "\n",
            "[ Train epoch: 49 ]\n",
            "\n",
            "Total average train accuarcy: 0.6525873736451827\n",
            "Total average train loss: 0.0020456879305839537\n",
            "\n",
            "[ Test epoch: 49 ]\n",
            "\n",
            "Total average test accuarcy: 0.8234\n",
            "Total average test loss: 0.0015672448515892028\n",
            "\n",
            "Time elapsed: 876.1070349216461\n",
            "\n",
            "[ Train epoch: 50 ]\n",
            "\n",
            "Total average train accuarcy: 0.6720183467790294\n",
            "Total average train loss: 0.0019895522832870482\n",
            "\n",
            "[ Test epoch: 50 ]\n",
            "\n",
            "Total average test accuarcy: 0.8265\n",
            "Total average test loss: 0.001537361526489258\n",
            "\n",
            "Time elapsed: 893.2479348182678\n",
            "\n",
            "[ Train epoch: 51 ]\n",
            "\n",
            "Total average train accuarcy: 0.6208302123109277\n",
            "Total average train loss: 0.002105348386764526\n",
            "\n",
            "[ Test epoch: 51 ]\n",
            "\n",
            "Total average test accuarcy: 0.8122\n",
            "Total average test loss: 0.001621517825126648\n",
            "\n",
            "Time elapsed: 910.5347595214844\n",
            "\n",
            "[ Train epoch: 52 ]\n",
            "\n",
            "Total average train accuarcy: 0.6656350261586922\n",
            "Total average train loss: 0.0020157741594314573\n",
            "\n",
            "[ Test epoch: 52 ]\n",
            "\n",
            "Total average test accuarcy: 0.8272\n",
            "Total average test loss: 0.0015378102660179138\n",
            "\n",
            "Time elapsed: 927.8340218067169\n",
            "\n",
            "[ Train epoch: 53 ]\n",
            "\n",
            "Total average train accuarcy: 0.6529765242131647\n",
            "Total average train loss: 0.002047601728439331\n",
            "\n",
            "[ Test epoch: 53 ]\n",
            "\n",
            "Total average test accuarcy: 0.8259\n",
            "Total average test loss: 0.0015804442882537842\n",
            "\n",
            "Time elapsed: 945.0470719337463\n",
            "\n",
            "[ Train epoch: 54 ]\n",
            "\n",
            "Total average train accuarcy: 0.6690838831804161\n",
            "Total average train loss: 0.0020000771856307983\n",
            "\n",
            "[ Test epoch: 54 ]\n",
            "\n",
            "Total average test accuarcy: 0.8246\n",
            "Total average test loss: 0.0015633205771446229\n",
            "\n",
            "Time elapsed: 962.2004790306091\n",
            "\n",
            "[ Train epoch: 55 ]\n",
            "\n",
            "Total average train accuarcy: 0.6263154350756632\n",
            "Total average train loss: 0.002096000626087189\n",
            "\n",
            "[ Test epoch: 55 ]\n",
            "\n",
            "Total average test accuarcy: 0.8191\n",
            "Total average test loss: 0.0016011645436286926\n",
            "\n",
            "Time elapsed: 979.509708404541\n",
            "\n",
            "[ Train epoch: 56 ]\n",
            "\n",
            "Total average train accuarcy: 0.6618092574526093\n",
            "Total average train loss: 0.002034610311985016\n",
            "\n",
            "[ Test epoch: 56 ]\n",
            "\n",
            "Total average test accuarcy: 0.8184\n",
            "Total average test loss: 0.0016027569770812988\n",
            "\n",
            "Time elapsed: 996.7913546562195\n",
            "\n",
            "[ Train epoch: 57 ]\n",
            "\n",
            "Total average train accuarcy: 0.6298171371811037\n",
            "Total average train loss: 0.0020853902578353884\n",
            "\n",
            "[ Test epoch: 57 ]\n",
            "\n",
            "Total average test accuarcy: 0.8226\n",
            "Total average test loss: 0.001593724238872528\n",
            "\n",
            "Time elapsed: 1014.0221378803253\n",
            "\n",
            "[ Train epoch: 58 ]\n",
            "\n",
            "Total average train accuarcy: 0.6167376980593803\n",
            "Total average train loss: 0.002115497078895569\n",
            "\n",
            "[ Test epoch: 58 ]\n",
            "\n",
            "Total average test accuarcy: 0.8142\n",
            "Total average test loss: 0.0016235031247138977\n",
            "\n",
            "Time elapsed: 1031.26890873909\n",
            "\n",
            "[ Train epoch: 59 ]\n",
            "\n",
            "Total average train accuarcy: 0.6434039124363473\n",
            "Total average train loss: 0.0020806840014457703\n",
            "\n",
            "[ Test epoch: 59 ]\n",
            "\n",
            "Total average test accuarcy: 0.8191\n",
            "Total average test loss: 0.0015968925595283509\n",
            "\n",
            "Time elapsed: 1048.56343460083\n",
            "\n",
            "[ Train epoch: 60 ]\n",
            "\n",
            "Total average train accuarcy: 0.6416876607455088\n",
            "Total average train loss: 0.0020516250348091127\n",
            "\n",
            "[ Test epoch: 60 ]\n",
            "\n",
            "Total average test accuarcy: 0.8281\n",
            "Total average test loss: 0.0015802499055862426\n",
            "\n",
            "Time elapsed: 1065.7523550987244\n",
            "\n",
            "[ Train epoch: 61 ]\n",
            "\n",
            "Total average train accuarcy: 0.6588582165328006\n",
            "Total average train loss: 0.0020147950768470762\n",
            "\n",
            "[ Test epoch: 61 ]\n",
            "\n",
            "Total average test accuarcy: 0.832\n",
            "Total average test loss: 0.0015629602789878846\n",
            "\n",
            "Time elapsed: 1082.9330134391785\n",
            "\n",
            "[ Train epoch: 62 ]\n",
            "\n",
            "Total average train accuarcy: 0.6523763135751159\n",
            "Total average train loss: 0.0020560589671134947\n",
            "\n",
            "[ Test epoch: 62 ]\n",
            "\n",
            "Total average test accuarcy: 0.8276\n",
            "Total average test loss: 0.0015940134525299072\n",
            "\n",
            "Time elapsed: 1100.1083371639252\n",
            "\n",
            "[ Train epoch: 63 ]\n",
            "\n",
            "Total average train accuarcy: 0.6726928304572278\n",
            "Total average train loss: 0.001969098801612854\n",
            "\n",
            "[ Test epoch: 63 ]\n",
            "\n",
            "Total average test accuarcy: 0.8352\n",
            "Total average test loss: 0.0015263528943061828\n",
            "\n",
            "Time elapsed: 1117.3571772575378\n",
            "\n",
            "[ Train epoch: 64 ]\n",
            "\n",
            "Total average train accuarcy: 0.6464503791634301\n",
            "Total average train loss: 0.0020585756254196167\n",
            "\n",
            "[ Test epoch: 64 ]\n",
            "\n",
            "Total average test accuarcy: 0.8329\n",
            "Total average test loss: 0.0015661176681518556\n",
            "\n",
            "Time elapsed: 1134.5421752929688\n",
            "\n",
            "[ Train epoch: 65 ]\n",
            "\n",
            "Total average train accuarcy: 0.6397343994599602\n",
            "Total average train loss: 0.0020701341772079466\n",
            "\n",
            "[ Test epoch: 65 ]\n",
            "\n",
            "Total average test accuarcy: 0.8305\n",
            "Total average test loss: 0.0015734998703002929\n",
            "\n",
            "Time elapsed: 1151.7825860977173\n",
            "\n",
            "[ Train epoch: 66 ]\n",
            "\n",
            "Total average train accuarcy: 0.6546160817861356\n",
            "Total average train loss: 0.0020219590640068053\n",
            "\n",
            "[ Test epoch: 66 ]\n",
            "\n",
            "Total average test accuarcy: 0.8295\n",
            "Total average test loss: 0.0015706340789794922\n",
            "\n",
            "Time elapsed: 1168.9651534557343\n",
            "\n",
            "[ Train epoch: 67 ]\n",
            "\n",
            "Total average train accuarcy: 0.6437887720632017\n",
            "Total average train loss: 0.002065902464389801\n",
            "\n",
            "[ Test epoch: 67 ]\n",
            "\n",
            "Total average test accuarcy: 0.8276\n",
            "Total average test loss: 0.001576500916481018\n",
            "\n",
            "Time elapsed: 1186.139111995697\n",
            "\n",
            "[ Train epoch: 68 ]\n",
            "\n",
            "Total average train accuarcy: 0.6587811011651753\n",
            "Total average train loss: 0.002025125470161438\n",
            "\n",
            "[ Test epoch: 68 ]\n",
            "\n",
            "Total average test accuarcy: 0.8326\n",
            "Total average test loss: 0.0015525529503822326\n",
            "\n",
            "Time elapsed: 1203.305640220642\n",
            "\n",
            "[ Train epoch: 69 ]\n",
            "\n",
            "Total average train accuarcy: 0.6670438430241786\n",
            "Total average train loss: 0.00203125581741333\n",
            "\n",
            "[ Test epoch: 69 ]\n",
            "\n",
            "Total average test accuarcy: 0.8341\n",
            "Total average test loss: 0.0015418213367462158\n",
            "\n",
            "Time elapsed: 1220.5396897792816\n",
            "\n",
            "[ Train epoch: 70 ]\n",
            "\n",
            "Total average train accuarcy: 0.6567457503234796\n",
            "Total average train loss: 0.002042442572116852\n",
            "\n",
            "[ Test epoch: 70 ]\n",
            "\n",
            "Total average test accuarcy: 0.8298\n",
            "Total average test loss: 0.0015695697903633117\n",
            "\n",
            "Time elapsed: 1237.809696674347\n",
            "\n",
            "[ Train epoch: 71 ]\n",
            "\n",
            "Total average train accuarcy: 0.6453813971169965\n",
            "Total average train loss: 0.002063905425071716\n",
            "\n",
            "[ Test epoch: 71 ]\n",
            "\n",
            "Total average test accuarcy: 0.8316\n",
            "Total average test loss: 0.0015538272976875305\n",
            "\n",
            "Time elapsed: 1254.9529814720154\n",
            "\n",
            "[ Train epoch: 72 ]\n",
            "\n",
            "Total average train accuarcy: 0.6536429936118644\n",
            "Total average train loss: 0.002033726236820221\n",
            "\n",
            "[ Test epoch: 72 ]\n",
            "\n",
            "Total average test accuarcy: 0.8332\n",
            "Total average test loss: 0.00155281583070755\n",
            "\n",
            "Time elapsed: 1272.2096600532532\n",
            "\n",
            "[ Train epoch: 73 ]\n",
            "\n",
            "Total average train accuarcy: 0.6602806485521447\n",
            "Total average train loss: 0.002012241892814636\n",
            "\n",
            "[ Test epoch: 73 ]\n",
            "\n",
            "Total average test accuarcy: 0.8337\n",
            "Total average test loss: 0.0015501561999320985\n",
            "\n",
            "Time elapsed: 1289.5085153579712\n",
            "\n",
            "[ Train epoch: 74 ]\n",
            "\n",
            "Total average train accuarcy: 0.6529738558120819\n",
            "Total average train loss: 0.002053682405948639\n",
            "\n",
            "[ Test epoch: 74 ]\n",
            "\n",
            "Total average test accuarcy: 0.8324\n",
            "Total average test loss: 0.001553486180305481\n",
            "\n",
            "Time elapsed: 1306.7129969596863\n",
            "\n",
            "[ Train epoch: 75 ]\n",
            "\n",
            "Total average train accuarcy: 0.6806246347949547\n",
            "Total average train loss: 0.001988318974971771\n",
            "\n",
            "[ Test epoch: 75 ]\n",
            "\n",
            "Total average test accuarcy: 0.8365\n",
            "Total average test loss: 0.0015266628742218017\n",
            "\n",
            "Time elapsed: 1323.887579202652\n",
            "\n",
            "[ Train epoch: 76 ]\n",
            "\n",
            "Total average train accuarcy: 0.6409432750519145\n",
            "Total average train loss: 0.002074466722011566\n",
            "\n",
            "[ Test epoch: 76 ]\n",
            "\n",
            "Total average test accuarcy: 0.8302\n",
            "Total average test loss: 0.0015767809629440308\n",
            "\n",
            "Time elapsed: 1341.1074781417847\n",
            "\n",
            "[ Train epoch: 77 ]\n",
            "\n",
            "Total average train accuarcy: 0.6612229189125498\n",
            "Total average train loss: 0.0020336355376243593\n",
            "\n",
            "[ Test epoch: 77 ]\n",
            "\n",
            "Total average test accuarcy: 0.8272\n",
            "Total average test loss: 0.0015906786680221557\n",
            "\n",
            "Time elapsed: 1358.3811221122742\n",
            "\n",
            "[ Train epoch: 78 ]\n",
            "\n",
            "Total average train accuarcy: 0.6149370433154062\n",
            "Total average train loss: 0.002116583778858185\n",
            "\n",
            "[ Test epoch: 78 ]\n",
            "\n",
            "Total average test accuarcy: 0.823\n",
            "Total average test loss: 0.0016224591255187988\n",
            "\n",
            "Time elapsed: 1375.6179823875427\n",
            "\n",
            "[ Train epoch: 79 ]\n",
            "\n",
            "Total average train accuarcy: 0.6721074361364293\n",
            "Total average train loss: 0.002008250412940979\n",
            "\n",
            "[ Test epoch: 79 ]\n",
            "\n",
            "Total average test accuarcy: 0.828\n",
            "Total average test loss: 0.0015916736006736756\n",
            "\n",
            "Time elapsed: 1392.7803041934967\n",
            "\n",
            "[ Train epoch: 80 ]\n",
            "\n",
            "Total average train accuarcy: 0.6564949825706624\n",
            "Total average train loss: 0.002033616909980774\n",
            "\n",
            "[ Test epoch: 80 ]\n",
            "\n",
            "Total average test accuarcy: 0.8313\n",
            "Total average test loss: 0.001569108819961548\n",
            "\n",
            "Time elapsed: 1410.0252721309662\n",
            "\n",
            "[ Train epoch: 81 ]\n",
            "\n",
            "Total average train accuarcy: 0.6710292093522813\n",
            "Total average train loss: 0.0020034579277038575\n",
            "\n",
            "[ Test epoch: 81 ]\n",
            "\n",
            "Total average test accuarcy: 0.8329\n",
            "Total average test loss: 0.0015474805235862732\n",
            "\n",
            "Time elapsed: 1427.368718624115\n",
            "\n",
            "[ Train epoch: 82 ]\n",
            "\n",
            "Total average train accuarcy: 0.6615207366446179\n",
            "Total average train loss: 0.0020107462191581724\n",
            "\n",
            "[ Test epoch: 82 ]\n",
            "\n",
            "Total average test accuarcy: 0.8307\n",
            "Total average test loss: 0.0015696284174919128\n",
            "\n",
            "Time elapsed: 1444.5703659057617\n",
            "\n",
            "[ Train epoch: 83 ]\n",
            "\n",
            "Total average train accuarcy: 0.6715835571917771\n",
            "Total average train loss: 0.0020058923983573913\n",
            "\n",
            "[ Test epoch: 83 ]\n",
            "\n",
            "Total average test accuarcy: 0.8295\n",
            "Total average test loss: 0.0015835391759872436\n",
            "\n",
            "Time elapsed: 1461.7312767505646\n",
            "\n",
            "[ Train epoch: 84 ]\n",
            "\n",
            "Total average train accuarcy: 0.6550503639342256\n",
            "Total average train loss: 0.0020339475202560426\n",
            "\n",
            "[ Test epoch: 84 ]\n",
            "\n",
            "Total average test accuarcy: 0.8349\n",
            "Total average test loss: 0.0015506865739822388\n",
            "\n",
            "Time elapsed: 1479.0014991760254\n",
            "\n",
            "[ Train epoch: 85 ]\n",
            "\n",
            "Total average train accuarcy: 0.6076648166453483\n",
            "Total average train loss: 0.002140970776081085\n",
            "\n",
            "[ Test epoch: 85 ]\n",
            "\n",
            "Total average test accuarcy: 0.8252\n",
            "Total average test loss: 0.0016097619533538819\n",
            "\n",
            "Time elapsed: 1496.2554876804352\n",
            "\n",
            "[ Train epoch: 86 ]\n",
            "\n",
            "Total average train accuarcy: 0.6379857146506095\n",
            "Total average train loss: 0.0020566619062423706\n",
            "\n",
            "[ Test epoch: 86 ]\n",
            "\n",
            "Total average test accuarcy: 0.83\n",
            "Total average test loss: 0.0015821897745132447\n",
            "\n",
            "Time elapsed: 1513.4748313426971\n",
            "\n",
            "[ Train epoch: 87 ]\n",
            "\n",
            "Total average train accuarcy: 0.6459527492430028\n",
            "Total average train loss: 0.0020786052083969116\n",
            "\n",
            "[ Test epoch: 87 ]\n",
            "\n",
            "Total average test accuarcy: 0.8301\n",
            "Total average test loss: 0.0015754937291145325\n",
            "\n",
            "Time elapsed: 1530.7188889980316\n",
            "\n",
            "[ Train epoch: 88 ]\n",
            "\n",
            "Total average train accuarcy: 0.7008773310102976\n",
            "Total average train loss: 0.0019439615702629089\n",
            "\n",
            "[ Test epoch: 88 ]\n",
            "\n",
            "Total average test accuarcy: 0.8369\n",
            "Total average test loss: 0.0015253692030906677\n",
            "\n",
            "Time elapsed: 1547.8892180919647\n",
            "\n",
            "[ Train epoch: 89 ]\n",
            "\n",
            "Total average train accuarcy: 0.6444095438656184\n",
            "Total average train loss: 0.0020748834133148195\n",
            "\n",
            "[ Test epoch: 89 ]\n",
            "\n",
            "Total average test accuarcy: 0.8328\n",
            "Total average test loss: 0.001561545991897583\n",
            "\n",
            "Time elapsed: 1565.0044548511505\n",
            "\n",
            "[ Train epoch: 90 ]\n",
            "\n",
            "Total average train accuarcy: 0.7103492008802356\n",
            "Total average train loss: 0.0019218691611289978\n",
            "\n",
            "[ Test epoch: 90 ]\n",
            "\n",
            "Total average test accuarcy: 0.8372\n",
            "Total average test loss: 0.0015241249322891235\n",
            "\n",
            "Time elapsed: 1582.2164652347565\n",
            "\n",
            "[ Train epoch: 91 ]\n",
            "\n",
            "Total average train accuarcy: 0.6636342578792013\n",
            "Total average train loss: 0.0020283002853393557\n",
            "\n",
            "[ Test epoch: 91 ]\n",
            "\n",
            "Total average test accuarcy: 0.833\n",
            "Total average test loss: 0.0015500048518180846\n",
            "\n",
            "Time elapsed: 1599.4218282699585\n",
            "\n",
            "[ Train epoch: 92 ]\n",
            "\n",
            "Total average train accuarcy: 0.6868515051951609\n",
            "Total average train loss: 0.0019612088203430178\n",
            "\n",
            "[ Test epoch: 92 ]\n",
            "\n",
            "Total average test accuarcy: 0.833\n",
            "Total average test loss: 0.001544260334968567\n",
            "\n",
            "Time elapsed: 1616.5485649108887\n",
            "\n",
            "[ Train epoch: 93 ]\n",
            "\n",
            "Total average train accuarcy: 0.6953815485778684\n",
            "Total average train loss: 0.0019337367129325866\n",
            "\n",
            "[ Test epoch: 93 ]\n",
            "\n",
            "Total average test accuarcy: 0.831\n",
            "Total average test loss: 0.0015644431352615357\n",
            "\n",
            "Time elapsed: 1633.7490787506104\n",
            "\n",
            "[ Train epoch: 94 ]\n",
            "\n",
            "Total average train accuarcy: 0.6556964126299655\n",
            "Total average train loss: 0.00202288405418396\n",
            "\n",
            "[ Test epoch: 94 ]\n",
            "\n",
            "Total average test accuarcy: 0.829\n",
            "Total average test loss: 0.0015757046699523926\n",
            "\n",
            "Time elapsed: 1651.044320344925\n",
            "\n",
            "[ Train epoch: 95 ]\n",
            "\n",
            "Total average train accuarcy: 0.6781903205406064\n",
            "Total average train loss: 0.0019763169479370115\n",
            "\n",
            "[ Test epoch: 95 ]\n",
            "\n",
            "Total average test accuarcy: 0.8355\n",
            "Total average test loss: 0.0015274824500083922\n",
            "\n",
            "Time elapsed: 1668.2640118598938\n",
            "\n",
            "[ Train epoch: 96 ]\n",
            "\n",
            "Total average train accuarcy: 0.7001605050076584\n",
            "Total average train loss: 0.0019088845038414\n",
            "\n",
            "[ Test epoch: 96 ]\n",
            "\n",
            "Total average test accuarcy: 0.8372\n",
            "Total average test loss: 0.0015214658617973328\n",
            "\n",
            "Time elapsed: 1685.4108316898346\n",
            "\n",
            "[ Train epoch: 97 ]\n",
            "\n",
            "Total average train accuarcy: 0.6512533180038997\n",
            "Total average train loss: 0.002050349798202515\n",
            "\n",
            "[ Test epoch: 97 ]\n",
            "\n",
            "Total average test accuarcy: 0.8335\n",
            "Total average test loss: 0.0015424932956695557\n",
            "\n",
            "Time elapsed: 1702.662338733673\n",
            "\n",
            "[ Train epoch: 98 ]\n",
            "\n",
            "Total average train accuarcy: 0.661674431255929\n",
            "Total average train loss: 0.0020258273243904112\n",
            "\n",
            "[ Test epoch: 98 ]\n",
            "\n",
            "Total average test accuarcy: 0.8306\n",
            "Total average test loss: 0.0015619973778724671\n",
            "\n",
            "Time elapsed: 1719.9199018478394\n",
            "\n",
            "[ Train epoch: 99 ]\n",
            "\n",
            "Total average train accuarcy: 0.6470876409293309\n",
            "Total average train loss: 0.0020383547139167786\n",
            "\n",
            "[ Test epoch: 99 ]\n",
            "\n",
            "Total average test accuarcy: 0.8324\n",
            "Total average test loss: 0.001549377727508545\n",
            "\n",
            "Time elapsed: 1737.1259126663208\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}