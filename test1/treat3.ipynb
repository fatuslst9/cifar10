{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdluQj1WgsoQ",
    "outputId": "6ea1fbf3-e403-4fb4-984e-f533efaa3872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "[ Train epoch: 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total average train accuarcy: 0.43908\n",
      "Total average train loss: 0.012385207607746125\n",
      "\n",
      "[ test epoch: 1 ]\n",
      "\n",
      "Total average test accuarcy: 0.4726\n",
      "Total average test loss: 0.0014988248705863952\n",
      "\n",
      "Time elapsed: 20.68163561820984\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Total average train accuarcy: 0.57126\n",
      "Total average train loss: 0.00934203672170639\n",
      "\n",
      "[ test epoch: 2 ]\n",
      "\n",
      "Total average test accuarcy: 0.5289\n",
      "Total average test loss: 0.0013623518347740174\n",
      "\n",
      "Time elapsed: 41.45068669319153\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Total average train accuarcy: 0.63286\n",
      "Total average train loss: 0.0080896375644207\n",
      "\n",
      "[ test epoch: 3 ]\n",
      "\n",
      "Total average test accuarcy: 0.633\n",
      "Total average test loss: 0.0010551653623580932\n",
      "\n",
      "Time elapsed: 62.51956248283386\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Total average train accuarcy: 0.6729\n",
      "Total average train loss: 0.007254442191123962\n",
      "\n",
      "[ test epoch: 4 ]\n",
      "\n",
      "Total average test accuarcy: 0.665\n",
      "Total average test loss: 0.0009848629653453826\n",
      "\n",
      "Time elapsed: 83.7674617767334\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Total average train accuarcy: 0.701\n",
      "Total average train loss: 0.0066685744059085846\n",
      "\n",
      "[ test epoch: 5 ]\n",
      "\n",
      "Total average test accuarcy: 0.6869\n",
      "Total average test loss: 0.0009046690344810485\n",
      "\n",
      "Time elapsed: 105.12516164779663\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Total average train accuarcy: 0.71984\n",
      "Total average train loss: 0.006240247038602829\n",
      "\n",
      "[ test epoch: 6 ]\n",
      "\n",
      "Total average test accuarcy: 0.7021\n",
      "Total average test loss: 0.0008558587074279785\n",
      "\n",
      "Time elapsed: 126.67670822143555\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Total average train accuarcy: 0.7394\n",
      "Total average train loss: 0.005838235617876053\n",
      "\n",
      "[ test epoch: 7 ]\n",
      "\n",
      "Total average test accuarcy: 0.6331\n",
      "Total average test loss: 0.0010817235231399536\n",
      "\n",
      "Time elapsed: 148.30491137504578\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Total average train accuarcy: 0.75162\n",
      "Total average train loss: 0.005551160910725593\n",
      "\n",
      "[ test epoch: 8 ]\n",
      "\n",
      "Total average test accuarcy: 0.7023\n",
      "Total average test loss: 0.0009386533558368683\n",
      "\n",
      "Time elapsed: 170.05610156059265\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Total average train accuarcy: 0.76428\n",
      "Total average train loss: 0.005279470426440239\n",
      "\n",
      "[ test epoch: 9 ]\n",
      "\n",
      "Total average test accuarcy: 0.7277\n",
      "Total average test loss: 0.0007979396343231201\n",
      "\n",
      "Time elapsed: 191.88695287704468\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Total average train accuarcy: 0.77452\n",
      "Total average train loss: 0.0050819989812374115\n",
      "\n",
      "[ test epoch: 10 ]\n",
      "\n",
      "Total average test accuarcy: 0.6887\n",
      "Total average test loss: 0.0008985381484031677\n",
      "\n",
      "Time elapsed: 213.73278069496155\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Total average train accuarcy: 0.78472\n",
      "Total average train loss: 0.004843303088545799\n",
      "\n",
      "[ test epoch: 11 ]\n",
      "\n",
      "Total average test accuarcy: 0.762\n",
      "Total average test loss: 0.0006860519528388978\n",
      "\n",
      "Time elapsed: 235.70600771903992\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Total average train accuarcy: 0.79124\n",
      "Total average train loss: 0.0046680569678545\n",
      "\n",
      "[ test epoch: 12 ]\n",
      "\n",
      "Total average test accuarcy: 0.76\n",
      "Total average test loss: 0.0007072525978088379\n",
      "\n",
      "Time elapsed: 257.6785111427307\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Total average train accuarcy: 0.79948\n",
      "Total average train loss: 0.004520180957913399\n",
      "\n",
      "[ test epoch: 13 ]\n",
      "\n",
      "Total average test accuarcy: 0.7531\n",
      "Total average test loss: 0.0007600062787532807\n",
      "\n",
      "Time elapsed: 279.61303067207336\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Total average train accuarcy: 0.80718\n",
      "Total average train loss: 0.004321212633252144\n",
      "\n",
      "[ test epoch: 14 ]\n",
      "\n",
      "Total average test accuarcy: 0.7735\n",
      "Total average test loss: 0.000679889577627182\n",
      "\n",
      "Time elapsed: 301.57855129241943\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Total average train accuarcy: 0.81338\n",
      "Total average train loss: 0.004174678433537483\n",
      "\n",
      "[ test epoch: 15 ]\n",
      "\n",
      "Total average test accuarcy: 0.7924\n",
      "Total average test loss: 0.0006045586884021759\n",
      "\n",
      "Time elapsed: 323.5709059238434\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Total average train accuarcy: 0.81862\n",
      "Total average train loss: 0.004059465348720551\n",
      "\n",
      "[ test epoch: 16 ]\n",
      "\n",
      "Total average test accuarcy: 0.7841\n",
      "Total average test loss: 0.0006332422614097595\n",
      "\n",
      "Time elapsed: 345.49620366096497\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Total average train accuarcy: 0.82504\n",
      "Total average train loss: 0.003951847324371338\n",
      "\n",
      "[ test epoch: 17 ]\n",
      "\n",
      "Total average test accuarcy: 0.7927\n",
      "Total average test loss: 0.0006107740104198456\n",
      "\n",
      "Time elapsed: 367.49755811691284\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Total average train accuarcy: 0.82976\n",
      "Total average train loss: 0.003810946034789085\n",
      "\n",
      "[ test epoch: 18 ]\n",
      "\n",
      "Total average test accuarcy: 0.7757\n",
      "Total average test loss: 0.0006847604274749756\n",
      "\n",
      "Time elapsed: 389.4887478351593\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Total average train accuarcy: 0.83474\n",
      "Total average train loss: 0.0036828704637289046\n",
      "\n",
      "[ test epoch: 19 ]\n",
      "\n",
      "Total average test accuarcy: 0.7903\n",
      "Total average test loss: 0.0006257403194904328\n",
      "\n",
      "Time elapsed: 411.39894104003906\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Total average train accuarcy: 0.83828\n",
      "Total average train loss: 0.0036008396846055985\n",
      "\n",
      "[ test epoch: 20 ]\n",
      "\n",
      "Total average test accuarcy: 0.7002\n",
      "Total average test loss: 0.0009296492695808411\n",
      "\n",
      "Time elapsed: 433.36176562309265\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Total average train accuarcy: 0.843\n",
      "Total average train loss: 0.0035050525295734405\n",
      "\n",
      "[ test epoch: 21 ]\n",
      "\n",
      "Total average test accuarcy: 0.7753\n",
      "Total average test loss: 0.0006682536363601685\n",
      "\n",
      "Time elapsed: 455.34492564201355\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Total average train accuarcy: 0.84774\n",
      "Total average train loss: 0.003420917567610741\n",
      "\n",
      "[ test epoch: 22 ]\n",
      "\n",
      "Total average test accuarcy: 0.7968\n",
      "Total average test loss: 0.0006248601496219635\n",
      "\n",
      "Time elapsed: 477.327162027359\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Total average train accuarcy: 0.85098\n",
      "Total average train loss: 0.0033080477982759477\n",
      "\n",
      "[ test epoch: 23 ]\n",
      "\n",
      "Total average test accuarcy: 0.7989\n",
      "Total average test loss: 0.0006123454332351685\n",
      "\n",
      "Time elapsed: 499.2669427394867\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Total average train accuarcy: 0.85586\n",
      "Total average train loss: 0.0032266503447294236\n",
      "\n",
      "[ test epoch: 24 ]\n",
      "\n",
      "Total average test accuarcy: 0.7932\n",
      "Total average test loss: 0.000621826559305191\n",
      "\n",
      "Time elapsed: 521.22119140625\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Total average train accuarcy: 0.85998\n",
      "Total average train loss: 0.003125762352645397\n",
      "\n",
      "[ test epoch: 25 ]\n",
      "\n",
      "Total average test accuarcy: 0.8055\n",
      "Total average test loss: 0.0005917185783386231\n",
      "\n",
      "Time elapsed: 543.185564994812\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Total average train accuarcy: 0.86474\n",
      "Total average train loss: 0.003023676852881908\n",
      "\n",
      "[ test epoch: 26 ]\n",
      "\n",
      "Total average test accuarcy: 0.8092\n",
      "Total average test loss: 0.0005843010127544403\n",
      "\n",
      "Time elapsed: 565.2517414093018\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Total average train accuarcy: 0.8667\n",
      "Total average train loss: 0.002985966416299343\n",
      "\n",
      "[ test epoch: 27 ]\n",
      "\n",
      "Total average test accuarcy: 0.7822\n",
      "Total average test loss: 0.0006984224498271942\n",
      "\n",
      "Time elapsed: 587.1795072555542\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Total average train accuarcy: 0.86884\n",
      "Total average train loss: 0.0029034360238909722\n",
      "\n",
      "[ test epoch: 28 ]\n",
      "\n",
      "Total average test accuarcy: 0.8006\n",
      "Total average test loss: 0.0006418497502803803\n",
      "\n",
      "Time elapsed: 609.1416127681732\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Total average train accuarcy: 0.87266\n",
      "Total average train loss: 0.0028133075606822967\n",
      "\n",
      "[ test epoch: 29 ]\n",
      "\n",
      "Total average test accuarcy: 0.8251\n",
      "Total average test loss: 0.0005527653962373733\n",
      "\n",
      "Time elapsed: 631.1670620441437\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Total average train accuarcy: 0.87592\n",
      "Total average train loss: 0.0027655122768878936\n",
      "\n",
      "[ test epoch: 30 ]\n",
      "\n",
      "Total average test accuarcy: 0.7988\n",
      "Total average test loss: 0.0006177277863025666\n",
      "\n",
      "Time elapsed: 653.1469612121582\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Total average train accuarcy: 0.87748\n",
      "Total average train loss: 0.0026865600511431693\n",
      "\n",
      "[ test epoch: 31 ]\n",
      "\n",
      "Total average test accuarcy: 0.7818\n",
      "Total average test loss: 0.0007201366007328034\n",
      "\n",
      "Time elapsed: 675.1393473148346\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Total average train accuarcy: 0.8791\n",
      "Total average train loss: 0.0026535176713764668\n",
      "\n",
      "[ test epoch: 32 ]\n",
      "\n",
      "Total average test accuarcy: 0.7533\n",
      "Total average test loss: 0.0008994736015796661\n",
      "\n",
      "Time elapsed: 697.0722651481628\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Total average train accuarcy: 0.88308\n",
      "Total average train loss: 0.0025429529762268067\n",
      "\n",
      "[ test epoch: 33 ]\n",
      "\n",
      "Total average test accuarcy: 0.8151\n",
      "Total average test loss: 0.0006086446702480316\n",
      "\n",
      "Time elapsed: 718.9803354740143\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Total average train accuarcy: 0.8866\n",
      "Total average train loss: 0.0025248567044734954\n",
      "\n",
      "[ test epoch: 34 ]\n",
      "\n",
      "Total average test accuarcy: 0.8345\n",
      "Total average test loss: 0.0005400240570306778\n",
      "\n",
      "Time elapsed: 740.8537406921387\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Total average train accuarcy: 0.88734\n",
      "Total average train loss: 0.002481789882481098\n",
      "\n",
      "[ test epoch: 35 ]\n",
      "\n",
      "Total average test accuarcy: 0.8339\n",
      "Total average test loss: 0.0005205142617225647\n",
      "\n",
      "Time elapsed: 762.7603409290314\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Total average train accuarcy: 0.89102\n",
      "Total average train loss: 0.002393369137942791\n",
      "\n",
      "[ test epoch: 36 ]\n",
      "\n",
      "Total average test accuarcy: 0.8034\n",
      "Total average test loss: 0.0006391391694545746\n",
      "\n",
      "Time elapsed: 784.6657321453094\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Total average train accuarcy: 0.89532\n",
      "Total average train loss: 0.002320063484609127\n",
      "\n",
      "[ test epoch: 37 ]\n",
      "\n",
      "Total average test accuarcy: 0.8286\n",
      "Total average test loss: 0.0005706765234470368\n",
      "\n",
      "Time elapsed: 806.6043879985809\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Total average train accuarcy: 0.89452\n",
      "Total average train loss: 0.0023034615123271943\n",
      "\n",
      "[ test epoch: 38 ]\n",
      "\n",
      "Total average test accuarcy: 0.8036\n",
      "Total average test loss: 0.0006601826965808869\n",
      "\n",
      "Time elapsed: 828.5047998428345\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Total average train accuarcy: 0.89844\n",
      "Total average train loss: 0.0022297587877511977\n",
      "\n",
      "[ test epoch: 39 ]\n",
      "\n",
      "Total average test accuarcy: 0.8181\n",
      "Total average test loss: 0.0006199017345905304\n",
      "\n",
      "Time elapsed: 850.4148850440979\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Total average train accuarcy: 0.90116\n",
      "Total average train loss: 0.0021872178873419764\n",
      "\n",
      "[ test epoch: 40 ]\n",
      "\n",
      "Total average test accuarcy: 0.8307\n",
      "Total average test loss: 0.0005615886092185975\n",
      "\n",
      "Time elapsed: 872.5214955806732\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Total average train accuarcy: 0.90312\n",
      "Total average train loss: 0.0021558765053749083\n",
      "\n",
      "[ test epoch: 41 ]\n",
      "\n",
      "Total average test accuarcy: 0.8279\n",
      "Total average test loss: 0.0005830011665821076\n",
      "\n",
      "Time elapsed: 894.4097583293915\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Total average train accuarcy: 0.90478\n",
      "Total average train loss: 0.0021213228520751\n",
      "\n",
      "[ test epoch: 42 ]\n",
      "\n",
      "Total average test accuarcy: 0.8386\n",
      "Total average test loss: 0.0005391385138034821\n",
      "\n",
      "Time elapsed: 916.3583612442017\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Total average train accuarcy: 0.90468\n",
      "Total average train loss: 0.0020642472824454307\n",
      "\n",
      "[ test epoch: 43 ]\n",
      "\n",
      "Total average test accuarcy: 0.8294\n",
      "Total average test loss: 0.0005693216979503631\n",
      "\n",
      "Time elapsed: 938.2919435501099\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Total average train accuarcy: 0.90956\n",
      "Total average train loss: 0.00199598381832242\n",
      "\n",
      "[ test epoch: 44 ]\n",
      "\n",
      "Total average test accuarcy: 0.8202\n",
      "Total average test loss: 0.0006004050016403199\n",
      "\n",
      "Time elapsed: 960.2478897571564\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Total average train accuarcy: 0.91074\n",
      "Total average train loss: 0.001928376629948616\n",
      "\n",
      "[ test epoch: 45 ]\n",
      "\n",
      "Total average test accuarcy: 0.8321\n",
      "Total average test loss: 0.0005558035224676132\n",
      "\n",
      "Time elapsed: 982.1540353298187\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Total average train accuarcy: 0.91132\n",
      "Total average train loss: 0.0019388272745907308\n",
      "\n",
      "[ test epoch: 46 ]\n",
      "\n",
      "Total average test accuarcy: 0.799\n",
      "Total average test loss: 0.0006966531038284302\n",
      "\n",
      "Time elapsed: 1004.05770611763\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Total average train accuarcy: 0.9136\n",
      "Total average train loss: 0.0018635289953649044\n",
      "\n",
      "[ test epoch: 47 ]\n",
      "\n",
      "Total average test accuarcy: 0.8397\n",
      "Total average test loss: 0.0005397041827440262\n",
      "\n",
      "Time elapsed: 1026.0887665748596\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Total average train accuarcy: 0.9154\n",
      "Total average train loss: 0.0018537243743240834\n",
      "\n",
      "[ test epoch: 48 ]\n",
      "\n",
      "Total average test accuarcy: 0.839\n",
      "Total average test loss: 0.0005660786658525467\n",
      "\n",
      "Time elapsed: 1048.0107553005219\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Total average train accuarcy: 0.91802\n",
      "Total average train loss: 0.0017954128585755825\n",
      "\n",
      "[ test epoch: 49 ]\n",
      "\n",
      "Total average test accuarcy: 0.8163\n",
      "Total average test loss: 0.0006477882504463196\n",
      "\n",
      "Time elapsed: 1069.919818162918\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Total average train accuarcy: 0.91812\n",
      "Total average train loss: 0.0017756753800809383\n",
      "\n",
      "[ test epoch: 50 ]\n",
      "\n",
      "Total average test accuarcy: 0.8246\n",
      "Total average test loss: 0.0006216257274150849\n",
      "\n",
      "Time elapsed: 1091.870763540268\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Total average train accuarcy: 0.90984\n",
      "Total average train loss: 0.00254718703314662\n",
      "\n",
      "[ test epoch: 51 ]\n",
      "\n",
      "Total average test accuarcy: 0.812\n",
      "Total average test loss: 0.0006892577767372132\n",
      "\n",
      "Time elapsed: 1115.9628331661224\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Total average train accuarcy: 0.91106\n",
      "Total average train loss: 0.0024929023130238056\n",
      "\n",
      "[ test epoch: 52 ]\n",
      "\n",
      "Total average test accuarcy: 0.8017\n",
      "Total average test loss: 0.0006661672711372375\n",
      "\n",
      "Time elapsed: 1140.1034862995148\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Total average train accuarcy: 0.91326\n",
      "Total average train loss: 0.002449215335100889\n",
      "\n",
      "[ test epoch: 53 ]\n",
      "\n",
      "Total average test accuarcy: 0.8376\n",
      "Total average test loss: 0.0005514016062021256\n",
      "\n",
      "Time elapsed: 1164.1576981544495\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Total average train accuarcy: 0.91586\n",
      "Total average train loss: 0.002357872950732708\n",
      "\n",
      "[ test epoch: 54 ]\n",
      "\n",
      "Total average test accuarcy: 0.8282\n",
      "Total average test loss: 0.0006164040267467499\n",
      "\n",
      "Time elapsed: 1188.3064074516296\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Total average train accuarcy: 0.919\n",
      "Total average train loss: 0.0022941051660478116\n",
      "\n",
      "[ test epoch: 55 ]\n",
      "\n",
      "Total average test accuarcy: 0.8376\n",
      "Total average test loss: 0.0005647052645683288\n",
      "\n",
      "Time elapsed: 1212.3958814144135\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Total average train accuarcy: 0.91886\n",
      "Total average train loss: 0.002263195835649967\n",
      "\n",
      "[ test epoch: 56 ]\n",
      "\n",
      "Total average test accuarcy: 0.8087\n",
      "Total average test loss: 0.0006723185241222381\n",
      "\n",
      "Time elapsed: 1236.5117318630219\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Total average train accuarcy: 0.9223\n",
      "Total average train loss: 0.0021796992567181587\n",
      "\n",
      "[ test epoch: 57 ]\n",
      "\n",
      "Total average test accuarcy: 0.8339\n",
      "Total average test loss: 0.000577730280160904\n",
      "\n",
      "Time elapsed: 1260.5624566078186\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Total average train accuarcy: 0.92334\n",
      "Total average train loss: 0.0021589173405617474\n",
      "\n",
      "[ test epoch: 58 ]\n",
      "\n",
      "Total average test accuarcy: 0.8405\n",
      "Total average test loss: 0.0005854742348194122\n",
      "\n",
      "Time elapsed: 1284.618768453598\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Total average train accuarcy: 0.92384\n",
      "Total average train loss: 0.00213449223741889\n",
      "\n",
      "[ test epoch: 59 ]\n",
      "\n",
      "Total average test accuarcy: 0.8373\n",
      "Total average test loss: 0.0005700019419193268\n",
      "\n",
      "Time elapsed: 1308.6750690937042\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Total average train accuarcy: 0.926\n",
      "Total average train loss: 0.0020861874393373727\n",
      "\n",
      "[ test epoch: 60 ]\n",
      "\n",
      "Total average test accuarcy: 0.8242\n",
      "Total average test loss: 0.0006578242540359497\n",
      "\n",
      "Time elapsed: 1332.7646238803864\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Total average train accuarcy: 0.92892\n",
      "Total average train loss: 0.0019972288266569375\n",
      "\n",
      "[ test epoch: 61 ]\n",
      "\n",
      "Total average test accuarcy: 0.8292\n",
      "Total average test loss: 0.000620161485671997\n",
      "\n",
      "Time elapsed: 1356.8810477256775\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Total average train accuarcy: 0.92756\n",
      "Total average train loss: 0.002012016016021371\n",
      "\n",
      "[ test epoch: 62 ]\n",
      "\n",
      "Total average test accuarcy: 0.8323\n",
      "Total average test loss: 0.0006120422184467315\n",
      "\n",
      "Time elapsed: 1381.0808956623077\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Total average train accuarcy: 0.93008\n",
      "Total average train loss: 0.0019497356727719308\n",
      "\n",
      "[ test epoch: 63 ]\n",
      "\n",
      "Total average test accuarcy: 0.835\n",
      "Total average test loss: 0.0006262685000896454\n",
      "\n",
      "Time elapsed: 1405.2211990356445\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Total average train accuarcy: 0.93268\n",
      "Total average train loss: 0.001906760168671608\n",
      "\n",
      "[ test epoch: 64 ]\n",
      "\n",
      "Total average test accuarcy: 0.8215\n",
      "Total average test loss: 0.0006433190703392028\n",
      "\n",
      "Time elapsed: 1429.3180992603302\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Total average train accuarcy: 0.93238\n",
      "Total average train loss: 0.0018867401778697968\n",
      "\n",
      "[ test epoch: 65 ]\n",
      "\n",
      "Total average test accuarcy: 0.8405\n",
      "Total average test loss: 0.0006005393683910369\n",
      "\n",
      "Time elapsed: 1453.5161600112915\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Total average train accuarcy: 0.9318\n",
      "Total average train loss: 0.0019123132159560919\n",
      "\n",
      "[ test epoch: 66 ]\n",
      "\n",
      "Total average test accuarcy: 0.8356\n",
      "Total average test loss: 0.0006490287661552429\n",
      "\n",
      "Time elapsed: 1477.6725311279297\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Total average train accuarcy: 0.93494\n",
      "Total average train loss: 0.0018006598825007678\n",
      "\n",
      "[ test epoch: 67 ]\n",
      "\n",
      "Total average test accuarcy: 0.8303\n",
      "Total average test loss: 0.0006491813421249389\n",
      "\n",
      "Time elapsed: 1501.79119181633\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Total average train accuarcy: 0.93722\n",
      "Total average train loss: 0.0017701468601822852\n",
      "\n",
      "[ test epoch: 68 ]\n",
      "\n",
      "Total average test accuarcy: 0.8389\n",
      "Total average test loss: 0.0006409282803535462\n",
      "\n",
      "Time elapsed: 1525.9026532173157\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Total average train accuarcy: 0.93716\n",
      "Total average train loss: 0.0017719082566350697\n",
      "\n",
      "[ test epoch: 69 ]\n",
      "\n",
      "Total average test accuarcy: 0.8348\n",
      "Total average test loss: 0.0006144328117370605\n",
      "\n",
      "Time elapsed: 1549.9724416732788\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Total average train accuarcy: 0.93802\n",
      "Total average train loss: 0.001730856317281723\n",
      "\n",
      "[ test epoch: 70 ]\n",
      "\n",
      "Total average test accuarcy: 0.8406\n",
      "Total average test loss: 0.0006183611273765563\n",
      "\n",
      "Time elapsed: 1574.0822095870972\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Total average train accuarcy: 0.93958\n",
      "Total average train loss: 0.001733766800314188\n",
      "\n",
      "[ test epoch: 71 ]\n",
      "\n",
      "Total average test accuarcy: 0.8184\n",
      "Total average test loss: 0.0007275792956352233\n",
      "\n",
      "Time elapsed: 1598.1764500141144\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Total average train accuarcy: 0.93688\n",
      "Total average train loss: 0.0017711936988681555\n",
      "\n",
      "[ test epoch: 72 ]\n",
      "\n",
      "Total average test accuarcy: 0.8182\n",
      "Total average test loss: 0.0006756410717964173\n",
      "\n",
      "Time elapsed: 1622.2893557548523\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Total average train accuarcy: 0.94076\n",
      "Total average train loss: 0.0016434516937285661\n",
      "\n",
      "[ test epoch: 73 ]\n",
      "\n",
      "Total average test accuarcy: 0.8445\n",
      "Total average test loss: 0.0006066734373569489\n",
      "\n",
      "Time elapsed: 1646.3947699069977\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Total average train accuarcy: 0.94092\n",
      "Total average train loss: 0.0016419958768039943\n",
      "\n",
      "[ test epoch: 74 ]\n",
      "\n",
      "Total average test accuarcy: 0.8204\n",
      "Total average test loss: 0.0007205245971679688\n",
      "\n",
      "Time elapsed: 1670.5464215278625\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Total average train accuarcy: 0.94324\n",
      "Total average train loss: 0.00159504708096385\n",
      "\n",
      "[ test epoch: 75 ]\n",
      "\n",
      "Total average test accuarcy: 0.8418\n",
      "Total average test loss: 0.0006225907981395721\n",
      "\n",
      "Time elapsed: 1694.700267314911\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Total average train accuarcy: 0.9435\n",
      "Total average train loss: 0.0016067950940877199\n",
      "\n",
      "[ test epoch: 76 ]\n",
      "\n",
      "Total average test accuarcy: 0.836\n",
      "Total average test loss: 0.0006539785265922547\n",
      "\n",
      "Time elapsed: 1718.8042657375336\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Total average train accuarcy: 0.94428\n",
      "Total average train loss: 0.0015300673317909241\n",
      "\n",
      "[ test epoch: 77 ]\n",
      "\n",
      "Total average test accuarcy: 0.8387\n",
      "Total average test loss: 0.0006257604122161865\n",
      "\n",
      "Time elapsed: 1742.9305436611176\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Total average train accuarcy: 0.94484\n",
      "Total average train loss: 0.0015156984354555607\n",
      "\n",
      "[ test epoch: 78 ]\n",
      "\n",
      "Total average test accuarcy: 0.845\n",
      "Total average test loss: 0.0006208457946777344\n",
      "\n",
      "Time elapsed: 1767.025750875473\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Total average train accuarcy: 0.94494\n",
      "Total average train loss: 0.001557566249333322\n",
      "\n",
      "[ test epoch: 79 ]\n",
      "\n",
      "Total average test accuarcy: 0.8382\n",
      "Total average test loss: 0.0006600147247314453\n",
      "\n",
      "Time elapsed: 1791.092708349228\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Total average train accuarcy: 0.94728\n",
      "Total average train loss: 0.0014714894741028547\n",
      "\n",
      "[ test epoch: 80 ]\n",
      "\n",
      "Total average test accuarcy: 0.827\n",
      "Total average test loss: 0.0006971858620643615\n",
      "\n",
      "Time elapsed: 1815.347512960434\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Total average train accuarcy: 0.94702\n",
      "Total average train loss: 0.001475382743962109\n",
      "\n",
      "[ test epoch: 81 ]\n",
      "\n",
      "Total average test accuarcy: 0.8235\n",
      "Total average test loss: 0.0006928219258785248\n",
      "\n",
      "Time elapsed: 1839.4451291561127\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Total average train accuarcy: 0.94716\n",
      "Total average train loss: 0.0014761775579303503\n",
      "\n",
      "[ test epoch: 82 ]\n",
      "\n",
      "Total average test accuarcy: 0.8235\n",
      "Total average test loss: 0.0007082619071006775\n",
      "\n",
      "Time elapsed: 1863.5844473838806\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Total average train accuarcy: 0.94828\n",
      "Total average train loss: 0.0014500471281260253\n",
      "\n",
      "[ test epoch: 83 ]\n",
      "\n",
      "Total average test accuarcy: 0.8364\n",
      "Total average test loss: 0.0006712585866451263\n",
      "\n",
      "Time elapsed: 1887.7229969501495\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Total average train accuarcy: 0.94952\n",
      "Total average train loss: 0.0014183863846212626\n",
      "\n",
      "[ test epoch: 84 ]\n",
      "\n",
      "Total average test accuarcy: 0.8169\n",
      "Total average test loss: 0.0007410453200340271\n",
      "\n",
      "Time elapsed: 1911.8762605190277\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Total average train accuarcy: 0.94966\n",
      "Total average train loss: 0.0014007310923561454\n",
      "\n",
      "[ test epoch: 85 ]\n",
      "\n",
      "Total average test accuarcy: 0.8313\n",
      "Total average test loss: 0.0007082735419273377\n",
      "\n",
      "Time elapsed: 1936.0699830055237\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Total average train accuarcy: 0.95064\n",
      "Total average train loss: 0.0013944463118165731\n",
      "\n",
      "[ test epoch: 86 ]\n",
      "\n",
      "Total average test accuarcy: 0.846\n",
      "Total average test loss: 0.0006262776792049408\n",
      "\n",
      "Time elapsed: 1960.3314192295074\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Total average train accuarcy: 0.95124\n",
      "Total average train loss: 0.0013463748137652874\n",
      "\n",
      "[ test epoch: 87 ]\n",
      "\n",
      "Total average test accuarcy: 0.8364\n",
      "Total average test loss: 0.0007160660624504089\n",
      "\n",
      "Time elapsed: 1984.531420469284\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Total average train accuarcy: 0.94996\n",
      "Total average train loss: 0.0014039498244598507\n",
      "\n",
      "[ test epoch: 88 ]\n",
      "\n",
      "Total average test accuarcy: 0.8369\n",
      "Total average test loss: 0.0007022856652736664\n",
      "\n",
      "Time elapsed: 2008.7296524047852\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Total average train accuarcy: 0.95356\n",
      "Total average train loss: 0.0013092269948869943\n",
      "\n",
      "[ test epoch: 89 ]\n",
      "\n",
      "Total average test accuarcy: 0.8423\n",
      "Total average test loss: 0.0006681394279003144\n",
      "\n",
      "Time elapsed: 2032.8773477077484\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Total average train accuarcy: 0.9541\n",
      "Total average train loss: 0.0012922261487320066\n",
      "\n",
      "[ test epoch: 90 ]\n",
      "\n",
      "Total average test accuarcy: 0.8423\n",
      "Total average test loss: 0.0006719989240169525\n",
      "\n",
      "Time elapsed: 2057.1047065258026\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Total average train accuarcy: 0.95374\n",
      "Total average train loss: 0.00129838408626616\n",
      "\n",
      "[ test epoch: 91 ]\n",
      "\n",
      "Total average test accuarcy: 0.8402\n",
      "Total average test loss: 0.0006439333200454712\n",
      "\n",
      "Time elapsed: 2081.282134771347\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Total average train accuarcy: 0.95564\n",
      "Total average train loss: 0.0012392476183176041\n",
      "\n",
      "[ test epoch: 92 ]\n",
      "\n",
      "Total average test accuarcy: 0.8383\n",
      "Total average test loss: 0.0006880297660827637\n",
      "\n",
      "Time elapsed: 2105.492116212845\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Total average train accuarcy: 0.9564\n",
      "Total average train loss: 0.0012329401985928417\n",
      "\n",
      "[ test epoch: 93 ]\n",
      "\n",
      "Total average test accuarcy: 0.8135\n",
      "Total average test loss: 0.0007801357209682464\n",
      "\n",
      "Time elapsed: 2129.714569568634\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Total average train accuarcy: 0.95334\n",
      "Total average train loss: 0.0013110690279304982\n",
      "\n",
      "[ test epoch: 94 ]\n",
      "\n",
      "Total average test accuarcy: 0.8469\n",
      "Total average test loss: 0.0006253476142883301\n",
      "\n",
      "Time elapsed: 2153.879711151123\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Total average train accuarcy: 0.95524\n",
      "Total average train loss: 0.001254518034607172\n",
      "\n",
      "[ test epoch: 95 ]\n",
      "\n",
      "Total average test accuarcy: 0.8283\n",
      "Total average test loss: 0.0007736505150794983\n",
      "\n",
      "Time elapsed: 2178.1423478126526\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Total average train accuarcy: 0.95892\n",
      "Total average train loss: 0.0011693421474844217\n",
      "\n",
      "[ test epoch: 96 ]\n",
      "\n",
      "Total average test accuarcy: 0.8435\n",
      "Total average test loss: 0.0006863081693649291\n",
      "\n",
      "Time elapsed: 2202.4815855026245\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Total average train accuarcy: 0.95444\n",
      "Total average train loss: 0.0012626728211715817\n",
      "\n",
      "[ test epoch: 97 ]\n",
      "\n",
      "Total average test accuarcy: 0.8345\n",
      "Total average test loss: 0.0007105497777462005\n",
      "\n",
      "Time elapsed: 2226.808814764023\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Total average train accuarcy: 0.9559\n",
      "Total average train loss: 0.0012273601281642913\n",
      "\n",
      "[ test epoch: 98 ]\n",
      "\n",
      "Total average test accuarcy: 0.8215\n",
      "Total average test loss: 0.0008210952341556549\n",
      "\n",
      "Time elapsed: 2251.1539430618286\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Total average train accuarcy: 0.9573\n",
      "Total average train loss: 0.0011704644991084934\n",
      "\n",
      "[ test epoch: 99 ]\n",
      "\n",
      "Total average test accuarcy: 0.8478\n",
      "Total average test loss: 0.0006755565285682678\n",
      "\n",
      "Time elapsed: 2275.537479877472\n",
      "\n",
      "[ Train epoch: 100 ]\n",
      "\n",
      "Total average train accuarcy: 0.96008\n",
      "Total average train loss: 0.0011152302669174968\n",
      "\n",
      "[ test epoch: 100 ]\n",
      "\n",
      "Total average test accuarcy: 0.8149\n",
      "Total average test loss: 0.0008256303310394287\n",
      "\n",
      "Time elapsed: 2299.8631331920624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models import resnet\n",
    "\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        \n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        \n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "net = resnet18()\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    \n",
    "    epoch+=1\n",
    "\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        current_correct = predicted.eq(targets).sum().item()\n",
    "        \n",
    "        correct += current_correct\n",
    "\n",
    "\n",
    "    print('\\nTotal average train accuarcy:', correct / total)\n",
    "    print('Total average train loss:', train_loss / total)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    \n",
    "    epoch+=1\n",
    "    \n",
    "    print('\\n[ test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('\\nTotal average test accuarcy:', correct / total)\n",
    "    print('Total average test loss:', loss / total)\n",
    "\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(0, 50):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\nTime elapsed:', time.time() - start_time)\n",
    "    \n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)\n",
    "    \n",
    "for epoch in range(50, 100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\nTime elapsed:', time.time() - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
